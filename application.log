2023-06-15 19:30:34,806 - root -INFO -i am in the main method..
2023-06-15 19:30:34,807 - root -INFO -calling spark object
2023-06-15 19:30:34,807 - Create_spark -INFO -get_spark_object method started
2023-06-15 19:30:34,807 - Create_spark -INFO -master is local
2023-06-15 19:30:47,474 - Create_spark -INFO -Spark obejct created.....
2023-06-15 19:30:47,474 - root -INFO -Validating spark object..........
2023-06-15 19:30:47,475 - Validate -WARNING -started the get_current_date method...
2023-06-15 19:30:54,942 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 19:30:54,943 - Validate -WARNING -Validation done , go frwd...
2023-06-15 19:30:54,943 - root -INFO -Application done
2023-06-15 19:33:05,650 - root -INFO -i am in the main method..
2023-06-15 19:33:05,650 - root -INFO -calling spark object
2023-06-15 19:33:05,650 - Create_spark -INFO -get_spark_object method started
2023-06-15 19:33:05,650 - Create_spark -INFO -master is local
2023-06-15 19:33:17,386 - Create_spark -INFO -Spark obejct created.....
2023-06-15 19:33:17,386 - root -INFO -Validating spark object..........
2023-06-15 19:33:17,386 - Validate -WARNING -started the get_current_date method...
2023-06-15 19:33:24,647 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 19:33:24,648 - Validate -WARNING -Validation done , go frwd...
2023-06-15 19:33:24,648 - root -INFO -Application done
2023-06-15 19:34:29,842 - root -INFO -i am in the main method..
2023-06-15 19:34:29,842 - root -INFO -calling spark object
2023-06-15 19:34:29,842 - Create_spark -INFO -get_spark_object method started
2023-06-15 19:34:29,842 - Create_spark -INFO -master is local
2023-06-15 19:34:42,101 - Create_spark -INFO -Spark obejct created.....
2023-06-15 19:34:42,101 - root -INFO -Validating spark object..........
2023-06-15 19:34:42,102 - Validate -WARNING -started the get_current_date method...
2023-06-15 19:34:48,913 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 19:34:48,913 - Validate -WARNING -Validation done , go frwd...
2023-06-15 19:34:48,914 - root -INFO -Application done
2023-06-15 19:35:48,765 - root -INFO -i am in the main method..
2023-06-15 19:35:48,766 - root -INFO -calling spark object
2023-06-15 19:35:48,768 - Create_spark -INFO -get_spark_object method started
2023-06-15 19:35:48,768 - Create_spark -INFO -master is local
2023-06-15 19:36:01,137 - Create_spark -INFO -Spark obejct created.....
2023-06-15 19:36:01,137 - root -INFO -Validating spark object..........
2023-06-15 19:36:01,137 - Validate -WARNING -started the get_current_date method...
2023-06-15 19:36:08,505 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 19:36:08,506 - Validate -WARNING -Validation done , go frwd...
2023-06-15 19:36:08,506 - root -INFO -Application done
2023-06-15 19:49:33,424 - root -INFO -i am in the main method..
2023-06-15 19:49:33,424 - root -INFO -calling spark object
2023-06-15 19:49:33,425 - Create_spark -INFO -get_spark_object method started
2023-06-15 19:49:33,425 - Create_spark -INFO -master is local
2023-06-15 19:49:45,694 - Create_spark -INFO -Spark obejct created.....
2023-06-15 19:49:45,695 - root -INFO -Validating spark object..........
2023-06-15 19:49:45,695 - Validate -WARNING -started the get_current_date method...
2023-06-15 19:49:53,241 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 19:49:53,241 - Validate -WARNING -Validation done , go frwd...
2023-06-15 19:49:53,242 - root -INFO -reading file which is of > parquet 
2023-06-15 19:49:53,242 - Ingest -WARNING -load_files method started...
2023-06-15 19:49:54,850 - Ingest -WARNING -dataframe created successfully which is of parquet
2023-06-15 19:49:54,863 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 19:49:56,774 - root -INFO -Application done
2023-06-15 19:53:17,623 - root -INFO -i am in the main method..
2023-06-15 19:53:17,623 - root -INFO -calling spark object
2023-06-15 19:53:17,623 - Create_spark -INFO -get_spark_object method started
2023-06-15 19:53:17,623 - Create_spark -INFO -master is local
2023-06-15 19:53:29,660 - Create_spark -INFO -Spark obejct created.....
2023-06-15 19:53:29,661 - root -INFO -Validating spark object..........
2023-06-15 19:53:29,661 - Validate -WARNING -started the get_current_date method...
2023-06-15 19:53:37,328 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 19:53:37,328 - Validate -WARNING -Validation done , go frwd...
2023-06-15 19:53:37,329 - root -INFO -reading file which is of > parquet 
2023-06-15 19:53:37,329 - Ingest -WARNING -load_files method started...
2023-06-15 19:53:38,819 - Ingest -WARNING -dataframe created successfully which is of parquet
2023-06-15 19:53:38,830 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 19:53:40,659 - root -INFO -validating the dataframe...
2023-06-15 19:53:40,659 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 19:53:41,828 - Ingest -WARNING -Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338
2023-06-15 19:53:41,828 - root -INFO -Application done
2023-06-15 19:58:37,933 - root -INFO -i am in the main method..
2023-06-15 19:58:37,933 - root -INFO -calling spark object
2023-06-15 19:58:37,934 - Create_spark -INFO -get_spark_object method started
2023-06-15 19:58:37,934 - Create_spark -INFO -master is local
2023-06-15 19:58:50,367 - Create_spark -INFO -Spark obejct created.....
2023-06-15 19:58:50,367 - root -INFO -Validating spark object..........
2023-06-15 19:58:50,368 - Validate -WARNING -started the get_current_date method...
2023-06-15 19:58:57,905 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 19:58:57,906 - Validate -WARNING -Validation done , go frwd...
2023-06-15 19:58:57,907 - root -INFO -reading file which is of > csv 
2023-06-15 19:58:57,907 - Ingest -WARNING -load_files method started...
2023-06-15 20:00:00,296 - root -INFO -i am in the main method..
2023-06-15 20:00:00,297 - root -INFO -calling spark object
2023-06-15 20:00:00,297 - Create_spark -INFO -get_spark_object method started
2023-06-15 20:00:00,297 - Create_spark -INFO -master is local
2023-06-15 20:00:12,294 - Create_spark -INFO -Spark obejct created.....
2023-06-15 20:00:12,294 - root -INFO -Validating spark object..........
2023-06-15 20:00:12,295 - Validate -WARNING -started the get_current_date method...
2023-06-15 20:00:19,573 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 20:00:19,574 - Validate -WARNING -Validation done , go frwd...
2023-06-15 20:00:19,575 - root -INFO -reading file which is of > csv 
2023-06-15 20:00:19,575 - Ingest -WARNING -load_files method started...
2023-06-15 20:01:31,302 - root -INFO -i am in the main method..
2023-06-15 20:01:31,302 - root -INFO -calling spark object
2023-06-15 20:01:31,302 - Create_spark -INFO -get_spark_object method started
2023-06-15 20:01:31,303 - Create_spark -INFO -master is local
2023-06-15 20:01:43,415 - Create_spark -INFO -Spark obejct created.....
2023-06-15 20:01:43,415 - root -INFO -Validating spark object..........
2023-06-15 20:01:43,416 - Validate -WARNING -started the get_current_date method...
2023-06-15 20:01:50,914 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 20:01:50,914 - Validate -WARNING -Validation done , go frwd...
2023-06-15 20:01:50,915 - root -INFO -reading file which is of > parquet 
2023-06-15 20:01:50,915 - Ingest -WARNING -load_files method started...
2023-06-15 20:01:52,421 - Ingest -WARNING -dataframe created successfully which is of parquet
2023-06-15 20:01:52,432 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 20:01:54,189 - root -INFO -validating the dataframe...
2023-06-15 20:01:54,189 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 20:01:55,342 - Ingest -WARNING -Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338
2023-06-15 20:01:55,342 - root -INFO -reading file which is of > csv 
2023-06-15 20:01:55,343 - Ingest -WARNING -load_files method started...
2023-06-15 20:56:06,450 - root -INFO -i am in the main method..
2023-06-15 20:56:06,451 - root -INFO -calling spark object
2023-06-15 20:56:06,451 - Create_spark -INFO -get_spark_object method started
2023-06-15 20:56:06,451 - Create_spark -INFO -master is local
2023-06-15 20:56:20,850 - Create_spark -INFO -Spark obejct created.....
2023-06-15 20:56:20,851 - root -INFO -Validating spark object..........
2023-06-15 20:56:20,851 - Validate -WARNING -started the get_current_date method...
2023-06-15 20:56:28,597 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 20:56:28,597 - Validate -WARNING -Validation done , go frwd...
2023-06-15 20:56:28,598 - root -INFO -reading file which is of > parquet 
2023-06-15 20:56:28,598 - Ingest -WARNING -load_files method started...
2023-06-15 20:56:29,997 - Ingest -WARNING -dataframe created successfully which is of parquet
2023-06-15 20:56:30,008 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 20:56:31,616 - root -INFO -validating the dataframe...
2023-06-15 20:56:31,616 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 20:56:32,578 - Ingest -WARNING -Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338
2023-06-15 20:56:32,578 - root -INFO -reading file which is of > csv 
2023-06-15 20:56:32,579 - Ingest -WARNING -load_files method started...
2023-06-15 20:58:11,777 - root -INFO -i am in the main method..
2023-06-15 20:58:11,777 - root -INFO -calling spark object
2023-06-15 20:58:11,777 - Create_spark -INFO -get_spark_object method started
2023-06-15 20:58:11,777 - Create_spark -INFO -master is local
2023-06-15 20:58:23,911 - Create_spark -INFO -Spark obejct created.....
2023-06-15 20:58:23,911 - root -INFO -Validating spark object..........
2023-06-15 20:58:23,911 - Validate -WARNING -started the get_current_date method...
2023-06-15 20:58:31,319 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 20:58:31,320 - Validate -WARNING -Validation done , go frwd...
2023-06-15 20:58:31,321 - root -INFO -reading file which is of > parquet 
2023-06-15 20:58:31,321 - Ingest -WARNING -load_files method started...
2023-06-15 20:58:32,887 - Ingest -WARNING -dataframe created successfully which is of parquet
2023-06-15 20:58:32,900 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 20:58:34,710 - root -INFO -validating the dataframe...
2023-06-15 20:58:34,710 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 20:58:35,793 - Ingest -WARNING -Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338
2023-06-15 20:58:35,794 - root -INFO -reading file which is of > csv 
2023-06-15 20:58:35,794 - Ingest -WARNING -load_files method started...
2023-06-15 21:02:52,228 - root -INFO -i am in the main method..
2023-06-15 21:02:52,228 - root -INFO -calling spark object
2023-06-15 21:02:52,228 - Create_spark -INFO -get_spark_object method started
2023-06-15 21:02:52,229 - Create_spark -INFO -master is local
2023-06-15 21:03:05,108 - Create_spark -INFO -Spark obejct created.....
2023-06-15 21:03:05,108 - root -INFO -Validating spark object..........
2023-06-15 21:03:05,108 - Validate -WARNING -started the get_current_date method...
2023-06-15 21:03:13,171 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 21:03:13,171 - Validate -WARNING -Validation done , go frwd...
2023-06-15 21:03:13,171 - root -INFO -reading file which is of > parquet 
2023-06-15 21:03:13,172 - Ingest -WARNING -load_files method started...
2023-06-15 21:03:14,521 - Ingest -WARNING -dataframe created successfully which is of parquet
2023-06-15 21:03:14,531 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 21:03:16,242 - root -INFO -validating the dataframe...
2023-06-15 21:03:16,242 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 21:03:17,333 - Ingest -WARNING -Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338
2023-06-15 21:03:17,334 - root -INFO -reading file which is of > csv 
2023-06-15 21:03:17,334 - Ingest -WARNING -load_files method started...
2023-06-15 21:04:23,559 - root -INFO -i am in the main method..
2023-06-15 21:04:23,559 - root -INFO -calling spark object
2023-06-15 21:04:23,559 - Create_spark -INFO -get_spark_object method started
2023-06-15 21:04:23,559 - Create_spark -INFO -master is local
2023-06-15 21:04:35,061 - Create_spark -INFO -Spark obejct created.....
2023-06-15 21:04:35,061 - root -INFO -Validating spark object..........
2023-06-15 21:04:35,061 - Validate -WARNING -started the get_current_date method...
2023-06-15 21:04:42,676 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 21:04:42,676 - Validate -WARNING -Validation done , go frwd...
2023-06-15 21:04:42,676 - root -INFO -reading file which is of > parquet 
2023-06-15 21:04:42,677 - Ingest -WARNING -load_files method started...
2023-06-15 21:04:44,101 - Ingest -WARNING -dataframe created successfully which is of parquet
2023-06-15 21:04:44,114 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 21:04:45,764 - root -INFO -validating the dataframe...
2023-06-15 21:04:45,764 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 21:04:46,841 - Ingest -WARNING -Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338
2023-06-15 21:04:46,841 - root -INFO -reading file which is of > csv 
2023-06-15 21:04:46,842 - Ingest -WARNING -load_files method started...
2023-06-15 21:07:39,700 - root -INFO -i am in the main method..
2023-06-15 21:07:39,700 - root -INFO -calling spark object
2023-06-15 21:07:39,701 - Create_spark -INFO -get_spark_object method started
2023-06-15 21:07:39,701 - Create_spark -INFO -master is local
2023-06-15 21:07:50,471 - Create_spark -INFO -Spark obejct created.....
2023-06-15 21:07:50,472 - root -INFO -Validating spark object..........
2023-06-15 21:07:50,472 - Validate -WARNING -started the get_current_date method...
2023-06-15 21:07:56,957 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 21:07:56,957 - Validate -WARNING -Validation done , go frwd...
2023-06-15 21:07:56,957 - root -INFO -reading file which is of > parquet 
2023-06-15 21:07:56,958 - Ingest -WARNING -load_files method started
2023-06-15 21:07:58,163 - Ingest -WARNING -Load_files func done, go frwd..
2023-06-15 21:07:58,174 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 21:07:59,711 - root -INFO -validating the dataframe...
2023-06-15 21:07:59,711 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 21:08:00,683 - Ingest -WARNING -Number of records present in the DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string] are :: 28338
2023-06-15 21:08:00,684 - root -INFO -reading file which is of > csv 
2023-06-15 21:08:00,684 - Ingest -WARNING -load_files method started
2023-06-15 21:08:02,212 - Ingest -WARNING -Load_files func done, go frwd..
2023-06-15 21:08:02,505 - root -INFO -validating the dataframe...
2023-06-15 21:08:02,505 - Ingest -WARNING -here to count the records in the df_fact
2023-06-15 21:08:02,951 - root -INFO -Application done
2023-06-15 21:13:34,760 - root -INFO -i am in the main method..
2023-06-15 21:13:34,762 - root -INFO -calling spark object
2023-06-15 21:13:34,762 - Create_spark -INFO -get_spark_object method started
2023-06-15 21:13:34,762 - Create_spark -INFO -master is local
2023-06-15 21:13:46,909 - Create_spark -INFO -Spark obejct created.....
2023-06-15 21:13:46,910 - root -INFO -Validating spark object..........
2023-06-15 21:13:46,910 - Validate -WARNING -started the get_current_date method...
2023-06-15 21:13:54,968 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 21:13:54,968 - Validate -WARNING -Validation done , go frwd...
2023-06-15 21:13:54,969 - root -INFO -reading file which is of > parquet 
2023-06-15 21:13:54,969 - Ingest -WARNING -load_files method started
2023-06-15 21:13:56,462 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-15 21:13:56,478 - root -INFO -displaying the dataframe DataFrame[city: string, city_ascii: string, state_id: string, state_name: string, county_fips: int, county_name: string, lat: double, lng: double, population: int, density: int, timezone: string, zips: string]
2023-06-15 21:13:59,726 - root -INFO -validating the dataframe...
2023-06-15 21:13:59,726 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 21:14:00,685 - Ingest -WARNING -number of records 28338 :: 
2023-06-15 21:14:00,686 - root -INFO -reading file which is of > csv 
2023-06-15 21:14:00,686 - Ingest -WARNING -load_files method started
2023-06-15 21:14:01,581 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-15 21:14:01,730 - root -INFO -validating the dataframe...
2023-06-15 21:14:01,731 - Ingest -WARNING -here to count the records in the df_fact
2023-06-15 21:14:02,010 - Ingest -WARNING -number of records 12913 :: 
2023-06-15 21:14:02,010 - root -INFO -Application done
2023-06-15 21:39:25,460 - root -INFO -i am in the main method..
2023-06-15 21:39:25,460 - root -INFO -calling spark object
2023-06-15 21:39:25,460 - Create_spark -INFO -get_spark_object method started
2023-06-15 21:39:25,460 - Create_spark -INFO -master is local
2023-06-15 21:39:38,796 - Create_spark -INFO -Spark obejct created.....
2023-06-15 21:39:38,796 - root -INFO -Validating spark object..........
2023-06-15 21:39:38,796 - Validate -WARNING -started the get_current_date method...
2023-06-15 21:39:46,619 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 15))]
2023-06-15 21:39:46,619 - Validate -WARNING -Validation done , go frwd...
2023-06-15 21:39:46,619 - root -INFO -reading file which is of > parquet
2023-06-15 21:39:46,620 - Ingest -WARNING -load_files method started
2023-06-15 21:39:48,067 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-15 21:39:48,068 - root -INFO -displaying file
2023-06-15 21:39:49,679 - root -INFO -here to validate the df
2023-06-15 21:39:49,679 - Ingest -WARNING -here to count the records in the df_city
2023-06-15 21:39:50,592 - Ingest -WARNING -number of records 28338 :: 
2023-06-15 21:39:50,592 - root -INFO -checking for the files in the Fact...
2023-06-15 21:39:50,593 - root -INFO -reading file which is of > csv
2023-06-15 21:39:50,593 - Ingest -WARNING -load_files method started
2023-06-15 21:40:03,085 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-15 21:40:03,086 - root -INFO -displaying the df_fact dataframe
2023-06-15 21:40:03,552 - Ingest -WARNING -here to count the records in the df_fact
2023-06-15 21:40:05,234 - Ingest -WARNING -number of records 1329329 :: 
2023-06-15 21:40:05,234 - root -INFO -Application done
2023-06-16 11:46:41,378 - root -INFO -i am in the main method..
2023-06-16 11:46:41,381 - root -INFO -calling spark object
2023-06-16 11:46:41,382 - Create_spark -INFO -get_spark_object method started
2023-06-16 11:46:41,382 - Create_spark -INFO -master is local
2023-06-16 11:46:57,537 - Create_spark -INFO -Spark obejct created.....
2023-06-16 11:46:57,537 - root -INFO -Validating spark object..........
2023-06-16 11:46:57,537 - Validate -WARNING -started the get_current_date method...
2023-06-16 11:47:07,343 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 11:47:07,343 - Validate -WARNING -Validation done , go frwd...
2023-06-16 11:47:07,344 - root -INFO -reading file which is of > parquet
2023-06-16 11:47:07,344 - Ingest -WARNING -load_files method started
2023-06-16 11:47:08,962 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 11:47:08,962 - root -INFO -displaying file
2023-06-16 11:47:11,101 - root -INFO -here to validate the df
2023-06-16 11:47:11,101 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 11:47:12,308 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 11:47:12,308 - root -INFO -checking for the files in the Fact...
2023-06-16 11:47:12,309 - root -INFO -reading file which is of > csv
2023-06-16 11:47:12,309 - Ingest -WARNING -load_files method started
2023-06-16 11:47:24,221 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 11:47:24,221 - root -INFO -displaying the df_fact dataframe
2023-06-16 11:47:24,783 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 11:47:26,444 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 11:47:26,444 - root -INFO -implementing data_processing methods...
2023-06-16 11:47:26,444 - Data_processing -WARNING -data_clean method() started...
2023-06-16 11:47:26,445 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 11:47:26,543 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 11:47:26,587 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 11:47:27,483 - root -INFO -Application done
2023-06-16 11:49:57,502 - root -INFO -i am in the main method..
2023-06-16 11:49:57,503 - root -INFO -calling spark object
2023-06-16 11:49:57,503 - Create_spark -INFO -get_spark_object method started
2023-06-16 11:49:57,503 - Create_spark -INFO -master is local
2023-06-16 11:50:10,092 - Create_spark -INFO -Spark obejct created.....
2023-06-16 11:50:10,092 - root -INFO -Validating spark object..........
2023-06-16 11:50:10,092 - Validate -WARNING -started the get_current_date method...
2023-06-16 11:50:21,096 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 11:50:21,097 - Validate -WARNING -Validation done , go frwd...
2023-06-16 11:50:21,098 - root -INFO -reading file which is of > parquet
2023-06-16 11:50:21,098 - Ingest -WARNING -load_files method started
2023-06-16 11:50:22,655 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 11:50:22,655 - root -INFO -displaying file
2023-06-16 11:50:24,517 - root -INFO -here to validate the df
2023-06-16 11:50:24,517 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 11:50:25,744 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 11:50:25,744 - root -INFO -checking for the files in the Fact...
2023-06-16 11:50:25,745 - root -INFO -reading file which is of > csv
2023-06-16 11:50:25,745 - Ingest -WARNING -load_files method started
2023-06-16 11:50:36,412 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 11:50:36,413 - root -INFO -displaying the df_fact dataframe
2023-06-16 11:50:37,014 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 11:50:38,713 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 11:50:38,713 - root -INFO -implementing data_processing methods...
2023-06-16 11:50:38,713 - Data_processing -WARNING -data_clean method() started...
2023-06-16 11:50:38,713 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 11:50:38,786 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 11:50:38,826 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 11:50:38,950 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 11:50:39,632 - root -INFO -Application done
2023-06-16 11:56:03,482 - root -INFO -i am in the main method..
2023-06-16 11:56:03,483 - root -INFO -calling spark object
2023-06-16 11:56:03,483 - Create_spark -INFO -get_spark_object method started
2023-06-16 11:56:03,483 - Create_spark -INFO -master is local
2023-06-16 11:56:18,852 - Create_spark -INFO -Spark obejct created.....
2023-06-16 11:56:18,852 - root -INFO -Validating spark object..........
2023-06-16 11:56:18,852 - Validate -WARNING -started the get_current_date method...
2023-06-16 11:56:26,866 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 11:56:26,867 - Validate -WARNING -Validation done , go frwd...
2023-06-16 11:56:26,869 - root -INFO -reading file which is of > parquet
2023-06-16 11:56:26,869 - Ingest -WARNING -load_files method started
2023-06-16 11:56:28,415 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 11:56:28,415 - root -INFO -displaying file
2023-06-16 11:56:30,252 - root -INFO -here to validate the df
2023-06-16 11:56:30,252 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 11:56:31,285 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 11:56:31,285 - root -INFO -checking for the files in the Fact...
2023-06-16 11:56:31,285 - root -INFO -reading file which is of > csv
2023-06-16 11:56:31,286 - Ingest -WARNING -load_files method started
2023-06-16 11:56:41,809 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 11:56:41,809 - root -INFO -displaying the df_fact dataframe
2023-06-16 11:56:42,387 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 11:56:43,977 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 11:56:43,977 - root -INFO -implementing data_processing methods...
2023-06-16 11:56:43,978 - Data_processing -WARNING -data_clean method() started...
2023-06-16 11:56:43,978 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 11:56:44,058 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 11:56:44,093 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 11:56:44,224 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 11:56:44,907 - root -INFO -validating schema for the dataframes....
2023-06-16 11:56:44,909 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 11:56:44,912 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 11:56:44,912 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 11:56:44,912 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 11:56:44,912 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 11:56:44,913 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 11:56:44,913 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 11:56:44,913 - Validate -INFO -print_schema done, go frwd....
2023-06-16 11:56:44,913 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 11:56:44,915 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-16 11:56:44,916 - Validate -INFO -	StructField(presc_lname,StringType,true)
2023-06-16 11:56:44,916 - Validate -INFO -	StructField(presc_fname,StringType,true)
2023-06-16 11:56:44,916 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-16 11:56:44,916 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-16 11:56:44,917 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-16 11:56:44,917 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-16 11:56:44,918 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-16 11:56:44,919 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-16 11:56:44,919 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-16 11:56:44,919 - Validate -INFO -	StructField(years_of_exp,StringType,true)
2023-06-16 11:56:44,920 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-16 11:56:44,921 - Validate -INFO -print_schema done, go frwd....
2023-06-16 11:56:44,921 - root -INFO -Application done
2023-06-16 12:04:08,413 - root -INFO -i am in the main method..
2023-06-16 12:04:08,414 - root -INFO -calling spark object
2023-06-16 12:04:08,414 - Create_spark -INFO -get_spark_object method started
2023-06-16 12:04:08,414 - Create_spark -INFO -master is local
2023-06-16 12:04:20,599 - Create_spark -INFO -Spark obejct created.....
2023-06-16 12:04:20,599 - root -INFO -Validating spark object..........
2023-06-16 12:04:20,599 - Validate -WARNING -started the get_current_date method...
2023-06-16 12:04:28,104 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 12:04:28,105 - Validate -WARNING -Validation done , go frwd...
2023-06-16 12:04:28,105 - root -INFO -reading file which is of > parquet
2023-06-16 12:04:28,106 - Ingest -WARNING -load_files method started
2023-06-16 12:04:29,581 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:04:29,581 - root -INFO -displaying file
2023-06-16 12:04:31,391 - root -INFO -here to validate the df
2023-06-16 12:04:31,391 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 12:04:32,535 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 12:04:32,535 - root -INFO -checking for the files in the Fact...
2023-06-16 12:04:32,535 - root -INFO -reading file which is of > csv
2023-06-16 12:04:32,536 - Ingest -WARNING -load_files method started
2023-06-16 12:04:46,484 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:04:46,484 - root -INFO -displaying the df_fact dataframe
2023-06-16 12:04:47,045 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 12:04:48,662 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 12:04:48,663 - root -INFO -implementing data_processing methods...
2023-06-16 12:04:48,663 - Data_processing -WARNING -data_clean method() started...
2023-06-16 12:04:48,663 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 12:04:48,737 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 12:04:48,782 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 12:04:48,920 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 12:04:49,006 - Data_processing -WARNING -concat first and lname 
2023-06-16 12:04:49,042 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 12:04:49,059 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 12:04:49,740 - root -INFO -validating schema for the dataframes....
2023-06-16 12:04:49,740 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 12:04:49,742 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 12:04:49,742 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 12:04:49,742 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 12:04:49,742 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 12:04:49,743 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 12:04:49,743 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 12:04:49,743 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:04:49,743 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 12:04:49,745 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-16 12:04:49,745 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-16 12:04:49,746 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-16 12:04:49,746 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-16 12:04:49,746 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-16 12:04:49,746 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-16 12:04:49,746 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-16 12:04:49,746 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-16 12:04:49,747 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-16 12:04:49,747 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-16 12:04:49,747 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-16 12:04:49,747 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:04:49,748 - root -INFO -Application done
2023-06-16 12:08:44,329 - root -INFO -i am in the main method..
2023-06-16 12:08:44,329 - root -INFO -calling spark object
2023-06-16 12:08:44,330 - Create_spark -INFO -get_spark_object method started
2023-06-16 12:08:44,330 - Create_spark -INFO -master is local
2023-06-16 12:08:56,739 - Create_spark -INFO -Spark obejct created.....
2023-06-16 12:08:56,740 - root -INFO -Validating spark object..........
2023-06-16 12:08:56,740 - Validate -WARNING -started the get_current_date method...
2023-06-16 12:09:04,154 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 12:09:04,154 - Validate -WARNING -Validation done , go frwd...
2023-06-16 12:09:04,155 - root -INFO -reading file which is of > parquet
2023-06-16 12:09:04,157 - Ingest -WARNING -load_files method started
2023-06-16 12:09:05,597 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:09:05,597 - root -INFO -displaying file
2023-06-16 12:09:07,349 - root -INFO -here to validate the df
2023-06-16 12:09:07,349 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 12:09:08,518 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 12:09:08,518 - root -INFO -checking for the files in the Fact...
2023-06-16 12:09:08,520 - root -INFO -reading file which is of > csv
2023-06-16 12:09:08,520 - Ingest -WARNING -load_files method started
2023-06-16 12:09:18,777 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:09:18,777 - root -INFO -displaying the df_fact dataframe
2023-06-16 12:09:19,275 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 12:09:20,978 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 12:09:20,978 - root -INFO -implementing data_processing methods...
2023-06-16 12:09:20,978 - Data_processing -WARNING -data_clean method() started...
2023-06-16 12:09:20,979 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 12:09:21,057 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 12:09:21,101 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 12:09:21,227 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 12:09:21,307 - Data_processing -WARNING -concat first and lname 
2023-06-16 12:09:21,346 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 12:09:21,368 - Data_processing -WARNING -now check for null values in all columns
2023-06-16 12:09:21,796 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-16 12:09:21,796 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 12:10:06,825 - root -INFO -validating schema for the dataframes....
2023-06-16 12:10:06,826 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 12:10:06,828 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 12:10:06,829 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 12:10:06,829 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 12:10:06,829 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 12:10:06,829 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 12:10:06,829 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 12:10:06,830 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:10:06,830 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 12:10:06,832 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-06-16 12:10:06,832 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-06-16 12:10:06,833 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-06-16 12:10:06,833 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-06-16 12:10:06,833 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-06-16 12:10:06,833 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-06-16 12:10:06,833 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-06-16 12:10:06,834 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-06-16 12:10:06,834 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-06-16 12:10:06,834 - Validate -INFO -	StructField(Country_name,LongType,false)
2023-06-16 12:10:06,834 - Validate -INFO -	StructField(presc_fullname,LongType,false)
2023-06-16 12:10:06,834 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:10:06,835 - root -INFO -Application done
2023-06-16 12:11:51,133 - root -INFO -i am in the main method..
2023-06-16 12:11:51,133 - root -INFO -calling spark object
2023-06-16 12:11:51,134 - Create_spark -INFO -get_spark_object method started
2023-06-16 12:11:51,134 - Create_spark -INFO -master is local
2023-06-16 12:12:02,952 - Create_spark -INFO -Spark obejct created.....
2023-06-16 12:12:02,952 - root -INFO -Validating spark object..........
2023-06-16 12:12:02,952 - Validate -WARNING -started the get_current_date method...
2023-06-16 12:12:10,534 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 12:12:10,534 - Validate -WARNING -Validation done , go frwd...
2023-06-16 12:12:10,535 - root -INFO -reading file which is of > parquet
2023-06-16 12:12:10,535 - Ingest -WARNING -load_files method started
2023-06-16 12:12:11,875 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:12:11,875 - root -INFO -displaying file
2023-06-16 12:12:13,661 - root -INFO -here to validate the df
2023-06-16 12:12:13,661 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 12:12:14,786 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 12:12:14,786 - root -INFO -checking for the files in the Fact...
2023-06-16 12:12:14,787 - root -INFO -reading file which is of > csv
2023-06-16 12:12:14,787 - Ingest -WARNING -load_files method started
2023-06-16 12:12:25,166 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:12:25,166 - root -INFO -displaying the df_fact dataframe
2023-06-16 12:12:25,743 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 12:12:27,455 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 12:12:27,455 - root -INFO -implementing data_processing methods...
2023-06-16 12:12:27,455 - Data_processing -WARNING -data_clean method() started...
2023-06-16 12:12:27,456 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 12:12:27,527 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 12:12:27,563 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 12:12:27,692 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 12:12:27,769 - Data_processing -WARNING -concat first and lname 
2023-06-16 12:12:27,806 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 12:12:27,826 - Data_processing -WARNING -now check for null values in all columns
2023-06-16 12:12:28,340 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-16 12:12:28,398 - Data_processing -WARNING -successfully droped the null values....
2023-06-16 12:12:28,398 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 12:13:13,550 - root -INFO -validating schema for the dataframes....
2023-06-16 12:13:13,551 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 12:13:13,552 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 12:13:13,553 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 12:13:13,553 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 12:13:13,553 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 12:13:13,553 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 12:13:13,553 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 12:13:13,553 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:13:13,553 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 12:13:13,555 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-06-16 12:13:13,555 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-06-16 12:13:13,555 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-06-16 12:13:13,555 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-06-16 12:13:13,555 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-06-16 12:13:13,555 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-06-16 12:13:13,556 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-06-16 12:13:13,556 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-06-16 12:13:13,556 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-06-16 12:13:13,556 - Validate -INFO -	StructField(Country_name,LongType,false)
2023-06-16 12:13:13,556 - Validate -INFO -	StructField(presc_fullname,LongType,false)
2023-06-16 12:13:13,556 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:13:13,557 - root -INFO -Application done
2023-06-16 12:14:12,821 - root -INFO -i am in the main method..
2023-06-16 12:14:12,822 - root -INFO -calling spark object
2023-06-16 12:14:12,822 - Create_spark -INFO -get_spark_object method started
2023-06-16 12:14:12,822 - Create_spark -INFO -master is local
2023-06-16 12:14:24,991 - Create_spark -INFO -Spark obejct created.....
2023-06-16 12:14:24,992 - root -INFO -Validating spark object..........
2023-06-16 12:14:24,992 - Validate -WARNING -started the get_current_date method...
2023-06-16 12:14:32,562 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 12:14:32,562 - Validate -WARNING -Validation done , go frwd...
2023-06-16 12:14:32,563 - root -INFO -reading file which is of > parquet
2023-06-16 12:14:32,563 - Ingest -WARNING -load_files method started
2023-06-16 12:14:33,996 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:14:33,996 - root -INFO -displaying file
2023-06-16 12:14:35,680 - root -INFO -here to validate the df
2023-06-16 12:14:35,680 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 12:14:36,724 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 12:14:36,724 - root -INFO -checking for the files in the Fact...
2023-06-16 12:14:36,724 - root -INFO -reading file which is of > csv
2023-06-16 12:14:36,725 - Ingest -WARNING -load_files method started
2023-06-16 12:14:47,160 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:14:47,160 - root -INFO -displaying the df_fact dataframe
2023-06-16 12:14:47,714 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 12:14:49,329 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 12:14:49,329 - root -INFO -implementing data_processing methods...
2023-06-16 12:14:49,329 - Data_processing -WARNING -data_clean method() started...
2023-06-16 12:14:49,330 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 12:14:49,395 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 12:14:49,434 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 12:14:49,569 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 12:14:49,642 - Data_processing -WARNING -concat first and lname 
2023-06-16 12:14:49,680 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 12:14:49,695 - Data_processing -WARNING -now check for null values in all columns
2023-06-16 12:14:50,121 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-16 12:14:50,173 - Data_processing -WARNING -successfully droped the null values....
2023-06-16 12:14:50,529 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 12:15:36,532 - root -INFO -validating schema for the dataframes....
2023-06-16 12:15:36,532 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 12:15:36,534 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 12:15:36,534 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 12:15:36,534 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 12:15:36,534 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 12:15:36,535 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 12:15:36,535 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 12:15:36,535 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:15:36,535 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 12:15:36,538 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-06-16 12:15:36,539 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-06-16 12:15:36,539 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-06-16 12:15:36,539 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-06-16 12:15:36,539 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-06-16 12:15:36,539 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-06-16 12:15:36,540 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-06-16 12:15:36,540 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-06-16 12:15:36,540 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-06-16 12:15:36,540 - Validate -INFO -	StructField(Country_name,LongType,false)
2023-06-16 12:15:36,540 - Validate -INFO -	StructField(presc_fullname,LongType,false)
2023-06-16 12:15:36,540 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:15:36,541 - root -INFO -Application done
2023-06-16 12:16:29,340 - root -INFO -i am in the main method..
2023-06-16 12:16:29,341 - root -INFO -calling spark object
2023-06-16 12:16:29,343 - Create_spark -INFO -get_spark_object method started
2023-06-16 12:16:29,344 - Create_spark -INFO -master is local
2023-06-16 12:16:42,702 - Create_spark -INFO -Spark obejct created.....
2023-06-16 12:16:42,702 - root -INFO -Validating spark object..........
2023-06-16 12:16:42,702 - Validate -WARNING -started the get_current_date method...
2023-06-16 12:16:50,351 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 12:16:50,352 - Validate -WARNING -Validation done , go frwd...
2023-06-16 12:16:50,352 - root -INFO -reading file which is of > parquet
2023-06-16 12:16:50,353 - Ingest -WARNING -load_files method started
2023-06-16 12:16:51,923 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:16:51,923 - root -INFO -displaying file
2023-06-16 12:16:53,783 - root -INFO -here to validate the df
2023-06-16 12:16:53,783 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 12:16:54,948 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 12:16:54,948 - root -INFO -checking for the files in the Fact...
2023-06-16 12:16:54,949 - root -INFO -reading file which is of > csv
2023-06-16 12:16:54,949 - Ingest -WARNING -load_files method started
2023-06-16 12:17:06,201 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 12:17:06,201 - root -INFO -displaying the df_fact dataframe
2023-06-16 12:17:06,734 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 12:17:08,386 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 12:17:08,387 - root -INFO -implementing data_processing methods...
2023-06-16 12:17:08,387 - Data_processing -WARNING -data_clean method() started...
2023-06-16 12:17:08,388 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 12:17:08,477 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 12:17:08,519 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 12:17:08,712 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 12:17:08,787 - Data_processing -WARNING -concat first and lname 
2023-06-16 12:17:08,824 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 12:17:08,844 - Data_processing -WARNING -now check for null values in all columns
2023-06-16 12:17:09,413 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-16 12:17:09,472 - Data_processing -WARNING -successfully droped the null values....
2023-06-16 12:17:09,845 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 12:17:59,096 - root -INFO -validating schema for the dataframes....
2023-06-16 12:17:59,097 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 12:17:59,098 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 12:17:59,099 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 12:17:59,099 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 12:17:59,099 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 12:17:59,099 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 12:17:59,100 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 12:17:59,100 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:17:59,100 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 12:17:59,102 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-06-16 12:17:59,102 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(Country_name,LongType,false)
2023-06-16 12:17:59,103 - Validate -INFO -	StructField(presc_fullname,LongType,false)
2023-06-16 12:17:59,104 - Validate -INFO -print_schema done, go frwd....
2023-06-16 12:18:55,945 - root -INFO -Application done
2023-06-16 14:18:39,214 - root -INFO -i am in the main method..
2023-06-16 14:18:39,214 - root -INFO -calling spark object
2023-06-16 14:18:39,215 - Create_spark -INFO -get_spark_object method started
2023-06-16 14:18:39,215 - Create_spark -INFO -master is local
2023-06-16 14:18:50,817 - Create_spark -INFO -Spark obejct created.....
2023-06-16 14:18:50,817 - root -INFO -Validating spark object..........
2023-06-16 14:18:50,817 - Validate -WARNING -started the get_current_date method...
2023-06-16 14:18:56,100 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 14:18:56,100 - Validate -WARNING -Validation done , go frwd...
2023-06-16 14:18:56,100 - root -INFO -reading file which is of > parquet
2023-06-16 14:18:56,100 - Ingest -WARNING -load_files method started
2023-06-16 14:18:56,853 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 14:18:56,853 - root -INFO -displaying file
2023-06-16 14:18:57,811 - root -INFO -here to validate the df
2023-06-16 14:18:57,811 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 14:18:58,409 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 14:18:58,409 - root -INFO -checking for the files in the Fact...
2023-06-16 14:18:58,410 - root -INFO -reading file which is of > csv
2023-06-16 14:18:58,410 - Ingest -WARNING -load_files method started
2023-06-16 14:19:02,847 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 14:19:02,847 - root -INFO -displaying the df_fact dataframe
2023-06-16 14:19:03,053 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 14:19:03,746 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 14:19:03,747 - root -INFO -implementing data_processing methods...
2023-06-16 14:19:03,747 - Data_processing -WARNING -data_clean method() started...
2023-06-16 14:19:03,747 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 14:19:03,790 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 14:19:03,810 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 14:19:03,858 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 14:19:03,890 - Data_processing -WARNING -concat first and lname 
2023-06-16 14:19:03,912 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 14:19:03,923 - Data_processing -WARNING -now check for null values in all columns
2023-06-16 14:19:03,923 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-16 14:19:03,940 - Data_processing -WARNING -successfully droped the null values....
2023-06-16 14:19:03,940 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-16 14:19:04,120 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 14:19:23,355 - root -INFO -validating schema for the dataframes....
2023-06-16 14:19:23,355 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 14:19:23,357 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 14:19:23,357 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 14:19:23,358 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 14:19:23,358 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 14:19:23,358 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 14:19:23,358 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 14:19:23,358 - Validate -INFO -print_schema done, go frwd....
2023-06-16 14:19:23,358 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 14:19:23,360 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-06-16 14:19:23,360 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-06-16 14:19:23,360 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-06-16 14:19:23,360 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-06-16 14:19:23,360 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-06-16 14:19:23,361 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-06-16 14:19:23,361 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-06-16 14:19:23,361 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-06-16 14:19:23,361 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-06-16 14:19:23,361 - Validate -INFO -	StructField(Country_name,LongType,false)
2023-06-16 14:19:23,361 - Validate -INFO -	StructField(presc_fullname,LongType,false)
2023-06-16 14:19:23,361 - Validate -INFO -print_schema done, go frwd....
2023-06-16 14:19:42,780 - root -INFO -Application done
2023-06-16 14:27:24,640 - root -INFO -i am in the main method..
2023-06-16 14:27:24,640 - root -INFO -calling spark object
2023-06-16 14:27:24,640 - Create_spark -INFO -get_spark_object method started
2023-06-16 14:27:24,640 - Create_spark -INFO -master is local
2023-06-16 14:27:30,054 - Create_spark -INFO -Spark obejct created.....
2023-06-16 14:27:30,054 - root -INFO -Validating spark object..........
2023-06-16 14:27:30,054 - Validate -WARNING -started the get_current_date method...
2023-06-16 14:27:33,301 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 14:27:33,302 - Validate -WARNING -Validation done , go frwd...
2023-06-16 14:27:33,302 - root -INFO -reading file which is of > parquet
2023-06-16 14:27:33,302 - Ingest -WARNING -load_files method started
2023-06-16 14:27:33,905 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 14:27:33,905 - root -INFO -displaying file
2023-06-16 14:27:34,645 - root -INFO -here to validate the df
2023-06-16 14:27:34,645 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 14:27:35,161 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 14:27:35,161 - root -INFO -checking for the files in the Fact...
2023-06-16 14:27:35,161 - root -INFO -reading file which is of > csv
2023-06-16 14:27:35,162 - Ingest -WARNING -load_files method started
2023-06-16 14:27:39,510 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 14:27:39,511 - root -INFO -displaying the df_fact dataframe
2023-06-16 14:27:39,736 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 14:27:40,488 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 14:27:40,488 - root -INFO -implementing data_processing methods...
2023-06-16 14:27:40,488 - Data_processing -WARNING -data_clean method() started...
2023-06-16 14:27:40,488 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 14:27:40,525 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 14:27:40,543 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 14:27:40,599 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 14:27:40,629 - Data_processing -WARNING -concat first and lname 
2023-06-16 14:27:40,647 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 14:27:40,657 - Data_processing -WARNING -now check for null values in all columns
2023-06-16 14:27:40,657 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-16 14:27:40,678 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-16 14:27:43,368 - Data_processing -WARNING -successfully droped the null values....
2023-06-16 14:27:43,368 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-16 14:27:43,528 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 14:28:02,078 - root -INFO -validating schema for the dataframes....
2023-06-16 14:28:02,078 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 14:28:02,078 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 14:28:02,079 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 14:28:02,079 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 14:28:02,079 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 14:28:02,079 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 14:28:02,079 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 14:28:02,079 - Validate -INFO -print_schema done, go frwd....
2023-06-16 14:28:02,079 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(presc_id,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(presc_city,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(presc_state,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(presc_spclt,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(drug_name,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(tx_cnt,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(total_day_supply,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(total_drug_cost,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(years_of_exp,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(Country_name,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -	StructField(presc_fullname,LongType,false)
2023-06-16 14:28:02,080 - Validate -INFO -print_schema done, go frwd....
2023-06-16 14:28:20,244 - root -INFO -Application done
2023-06-16 14:46:59,087 - root -INFO -i am in the main method..
2023-06-16 14:46:59,088 - root -INFO -calling spark object
2023-06-16 14:46:59,088 - Create_spark -INFO -get_spark_object method started
2023-06-16 14:46:59,088 - Create_spark -INFO -master is local
2023-06-16 14:47:04,332 - Create_spark -INFO -Spark obejct created.....
2023-06-16 14:47:04,332 - root -INFO -Validating spark object..........
2023-06-16 14:47:04,332 - Validate -WARNING -started the get_current_date method...
2023-06-16 14:47:07,647 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 14:47:07,648 - Validate -WARNING -Validation done , go frwd...
2023-06-16 14:47:07,648 - root -INFO -reading file which is of > parquet
2023-06-16 14:47:07,648 - Ingest -WARNING -load_files method started
2023-06-16 14:47:08,278 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 14:47:08,278 - root -INFO -displaying file
2023-06-16 14:47:09,084 - root -INFO -here to validate the df
2023-06-16 14:47:09,084 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 14:47:09,643 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 14:47:09,643 - root -INFO -checking for the files in the Fact...
2023-06-16 14:47:09,644 - root -INFO -reading file which is of > csv
2023-06-16 14:47:09,644 - Ingest -WARNING -load_files method started
2023-06-16 14:47:14,158 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 14:47:14,158 - root -INFO -displaying the df_fact dataframe
2023-06-16 14:47:14,371 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 14:47:15,135 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 14:47:15,136 - root -INFO -implementing data_processing methods...
2023-06-16 14:47:15,136 - Data_processing -WARNING -data_clean method() started...
2023-06-16 14:47:15,136 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 14:47:15,181 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 14:47:15,204 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 14:47:15,263 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 14:47:15,297 - Data_processing -WARNING -concat first and lname 
2023-06-16 14:47:15,317 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 14:47:15,326 - Data_processing -WARNING -now check for null values in all columns
2023-06-16 14:47:15,326 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-16 14:47:15,347 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-16 14:47:18,672 - Data_processing -WARNING -successfully droped the null values....
2023-06-16 14:47:18,673 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-16 14:47:18,673 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 14:47:18,964 - root -INFO -validating schema for the dataframes....
2023-06-16 14:47:18,964 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 14:47:18,965 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 14:47:18,965 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 14:47:18,965 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 14:47:18,965 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 14:47:18,965 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 14:47:18,965 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 14:47:18,965 - Validate -INFO -print_schema done, go frwd....
2023-06-16 14:47:18,965 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 14:47:18,966 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-16 14:47:18,967 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-16 14:47:18,967 - Validate -INFO -print_schema done, go frwd....
2023-06-16 14:47:19,094 - root -INFO -Application done
2023-06-16 15:03:12,217 - root -INFO -i am in the main method..
2023-06-16 15:03:12,217 - root -INFO -calling spark object
2023-06-16 15:03:12,217 - Create_spark -INFO -get_spark_object method started
2023-06-16 15:03:12,217 - Create_spark -INFO -master is local
2023-06-16 15:03:18,120 - Create_spark -INFO -Spark obejct created.....
2023-06-16 15:03:18,120 - root -INFO -Validating spark object..........
2023-06-16 15:03:18,120 - Validate -WARNING -started the get_current_date method...
2023-06-16 15:03:21,774 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 16))]
2023-06-16 15:03:21,774 - Validate -WARNING -Validation done , go frwd...
2023-06-16 15:03:21,774 - root -INFO -reading file which is of > parquet
2023-06-16 15:03:21,774 - Ingest -WARNING -load_files method started
2023-06-16 15:03:22,436 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 15:03:22,436 - root -INFO -displaying file
2023-06-16 15:03:23,275 - root -INFO -here to validate the df
2023-06-16 15:03:23,275 - Ingest -WARNING -here to count the records in the df_city
2023-06-16 15:03:23,919 - Ingest -WARNING -number of records 28338 :: 
2023-06-16 15:03:23,919 - root -INFO -checking for the files in the Fact...
2023-06-16 15:03:23,920 - root -INFO -reading file which is of > csv
2023-06-16 15:03:23,920 - Ingest -WARNING -load_files method started
2023-06-16 15:03:28,261 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-16 15:03:28,262 - root -INFO -displaying the df_fact dataframe
2023-06-16 15:03:28,484 - Ingest -WARNING -here to count the records in the df_fact
2023-06-16 15:03:29,186 - Ingest -WARNING -number of records 1329329 :: 
2023-06-16 15:03:29,187 - root -INFO -implementing data_processing methods...
2023-06-16 15:03:29,187 - Data_processing -WARNING -data_clean method() started...
2023-06-16 15:03:29,187 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-16 15:03:29,229 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-16 15:03:29,251 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-16 15:03:29,309 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-16 15:03:29,339 - Data_processing -WARNING -concat first and lname 
2023-06-16 15:03:29,360 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-16 15:03:29,372 - Data_processing -WARNING -now check for null values in all columns
2023-06-16 15:03:29,372 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-16 15:03:29,391 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-16 15:03:32,242 - Data_processing -WARNING -successfully droped the null values....
2023-06-16 15:03:32,242 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-16 15:03:32,242 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-16 15:03:32,541 - root -INFO -validating schema for the dataframes....
2023-06-16 15:03:32,541 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-16 15:03:32,542 - Validate -INFO -	StructField(city,StringType,true)
2023-06-16 15:03:32,542 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-16 15:03:32,543 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-16 15:03:32,543 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-16 15:03:32,543 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-16 15:03:32,543 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-16 15:03:32,543 - Validate -INFO -print_schema done, go frwd....
2023-06-16 15:03:32,543 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-16 15:03:32,544 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-16 15:03:32,544 - Validate -INFO -print_schema done, go frwd....
2023-06-16 15:03:32,654 - root -INFO -checking for null values in dataframes...after processing 
2023-06-16 15:03:32,654 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-16 15:03:32,832 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-16 15:03:51,275 - root -INFO -Application done
2023-06-18 10:50:24,338 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 10:50:24,799 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 10:50:24,832 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 10:50:25,103 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 10:51:51,795 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 10:51:52,170 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 10:52:03,750 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 10:52:04,230 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 10:58:13,853 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 10:58:14,296 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 10:58:25,998 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 10:58:26,358 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 10:58:35,618 - root -ERROR -Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=1188>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-06-18 10:58:35,735 - root -ERROR -Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\lib\socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "C:\Spark_L\spark-3.2.3-bin-hadoop3.2\python\pyspark\context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "C:\Spark_L\spark-3.2.3-bin-hadoop3.2\python\pyspark\context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "C:\Spark_L\spark-3.2.3-bin-hadoop3.2\python\pyspark\sql\utils.py", line 111, in deco
    return f(*a, **kw)
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o13.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-06-18 10:59:24,625 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 10:59:25,072 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 10:59:36,369 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 10:59:36,743 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 11:23:03,955 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 11:23:04,400 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 11:23:15,187 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 11:23:15,572 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 11:47:39,226 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 11:47:39,634 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 11:47:50,733 - Validate -INFO -check for nulls method executing.......for df_presc
2023-06-18 11:47:51,110 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 11:48:00,883 - root -ERROR -Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
RuntimeError: reentrant call inside <_io.BufferedReader name=1212>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-06-18 11:48:00,888 - root -ERROR -Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\lib\socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "C:\Spark_L\spark-3.2.3-bin-hadoop3.2\python\pyspark\context.py", line 292, in signal_handler
    self.cancelAllJobs()
  File "C:\Spark_L\spark-3.2.3-bin-hadoop3.2\python\pyspark\context.py", line 1195, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\java_gateway.py", line 1321, in __call__
    return_value = get_return_value(
  File "C:\Spark_L\spark-3.2.3-bin-hadoop3.2\python\pyspark\sql\utils.py", line 111, in deco
    return f(*a, **kw)
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o13.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "C:\Users\lenovo\PycharmProjects\pythonProject7youtube\venv\lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2023-06-18 19:03:27,557 - root -INFO -i am in the main method..
2023-06-18 19:03:27,557 - root -INFO -calling spark object
2023-06-18 19:03:27,558 - Create_spark -INFO -get_spark_object method started
2023-06-18 19:03:27,558 - Create_spark -INFO -master is local
2023-06-18 19:03:35,350 - Create_spark -INFO -Spark obejct created.....
2023-06-18 19:03:35,350 - root -INFO -Validating spark object..........
2023-06-18 19:03:35,350 - Validate -WARNING -started the get_current_date method...
2023-06-18 19:03:39,864 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 18))]
2023-06-18 19:03:39,864 - Validate -WARNING -Validation done , go frwd...
2023-06-18 19:03:39,865 - root -INFO -reading file which is of > parquet
2023-06-18 19:03:39,865 - Ingest -WARNING -load_files method started
2023-06-18 19:03:40,801 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-18 19:03:40,802 - root -INFO -displaying file
2023-06-18 19:03:41,765 - root -INFO -here to validate the df
2023-06-18 19:03:41,765 - Ingest -WARNING -here to count the records in the df_city
2023-06-18 19:03:42,465 - Ingest -WARNING -number of records 28338 :: 
2023-06-18 19:03:42,465 - root -INFO -checking for the files in the Fact...
2023-06-18 19:03:42,466 - root -INFO -reading file which is of > csv
2023-06-18 19:03:42,466 - Ingest -WARNING -load_files method started
2023-06-18 19:03:47,233 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-18 19:03:47,233 - root -INFO -displaying the df_fact dataframe
2023-06-18 19:03:47,476 - Ingest -WARNING -here to count the records in the df_fact
2023-06-18 19:03:48,220 - Ingest -WARNING -number of records 1329329 :: 
2023-06-18 19:03:48,220 - root -INFO -implementing data_processing methods...
2023-06-18 19:03:48,220 - Data_processing -WARNING -data_clean method() started...
2023-06-18 19:03:48,220 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-18 19:03:48,263 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-18 19:03:48,282 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-18 19:03:48,340 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-18 19:03:48,384 - Data_processing -WARNING -concat first and lname 
2023-06-18 19:03:48,417 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-18 19:03:48,431 - Data_processing -WARNING -now check for null values in all columns
2023-06-18 19:03:48,431 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-18 19:03:48,453 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-18 19:03:51,361 - Data_processing -WARNING -successfully droped the null values....
2023-06-18 19:03:51,361 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-18 19:03:51,361 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-18 19:03:51,763 - root -INFO -validating schema for the dataframes....
2023-06-18 19:03:51,763 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-18 19:03:51,765 - Validate -INFO -	StructField(city,StringType,true)
2023-06-18 19:03:51,765 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-18 19:03:51,765 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-18 19:03:51,765 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-18 19:03:51,765 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-18 19:03:51,765 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-18 19:03:51,765 - Validate -INFO -print_schema done, go frwd....
2023-06-18 19:03:51,765 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-18 19:03:51,766 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-18 19:03:51,766 - Validate -INFO -print_schema done, go frwd....
2023-06-18 19:03:51,883 - root -INFO -checking for null values in dataframes...after processing 
2023-06-18 19:03:51,883 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-18 19:03:52,183 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-18 19:04:11,402 - root -INFO -data_transformation executing....
2023-06-18 19:04:11,403 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-18 19:04:11,403 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-18 19:04:11,428 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-18 19:04:11,465 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-18 19:04:11,515 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-18 19:04:11,515 - root -INFO -displaying the df_report_1
2023-06-18 19:04:19,526 - root -INFO -Application done
2023-06-19 08:58:34,585 - root -INFO -i am in the main method..
2023-06-19 08:58:34,585 - root -INFO -calling spark object
2023-06-19 08:58:34,585 - Create_spark -INFO -get_spark_object method started
2023-06-19 08:58:34,586 - Create_spark -INFO -master is local
2023-06-19 08:58:41,414 - Create_spark -INFO -Spark obejct created.....
2023-06-19 08:58:41,414 - root -INFO -Validating spark object..........
2023-06-19 08:58:41,415 - Validate -WARNING -started the get_current_date method...
2023-06-19 08:58:46,886 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 08:58:46,887 - Validate -WARNING -Validation done , go frwd...
2023-06-19 08:58:46,887 - root -INFO -reading file which is of > parquet
2023-06-19 08:58:46,887 - Ingest -WARNING -load_files method started
2023-06-19 08:58:47,769 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 08:58:47,769 - root -INFO -displaying file
2023-06-19 08:58:48,565 - root -INFO -here to validate the df
2023-06-19 08:58:48,565 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 08:58:49,083 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 08:58:49,083 - root -INFO -checking for the files in the Fact...
2023-06-19 08:58:49,083 - root -INFO -reading file which is of > csv
2023-06-19 08:58:49,083 - Ingest -WARNING -load_files method started
2023-06-19 08:58:54,772 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 08:58:54,772 - root -INFO -displaying the df_fact dataframe
2023-06-19 08:58:54,983 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 08:58:55,826 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 08:58:55,826 - root -INFO -implementing data_processing methods...
2023-06-19 08:58:55,826 - Data_processing -WARNING -data_clean method() started...
2023-06-19 08:58:55,826 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 08:58:55,869 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 08:58:55,892 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 08:58:55,945 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 08:58:55,976 - Data_processing -WARNING -concat first and lname 
2023-06-19 08:58:55,993 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 08:58:56,002 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 08:58:56,002 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 08:58:56,021 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 08:59:00,340 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 08:59:00,340 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 08:59:00,340 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 08:59:00,609 - root -INFO -validating schema for the dataframes....
2023-06-19 08:59:00,609 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 08:59:00,610 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 08:59:00,610 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 08:59:00,611 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 08:59:00,611 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 08:59:00,611 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 08:59:00,611 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 08:59:00,611 - Validate -INFO -print_schema done, go frwd....
2023-06-19 08:59:00,611 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 08:59:00,612 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 08:59:00,613 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 08:59:00,613 - Validate -INFO -print_schema done, go frwd....
2023-06-19 08:59:00,699 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 08:59:00,699 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 08:59:00,916 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 08:59:24,759 - root -INFO -data_transformation executing....
2023-06-19 08:59:24,759 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 08:59:24,760 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 08:59:24,782 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 08:59:24,815 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 08:59:24,862 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 08:59:24,862 - root -INFO -displaying the df_report_1
2023-06-19 08:59:33,572 - root -INFO -displaying data_report2 method....
2023-06-19 08:59:33,572 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 08:59:33,572 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 08:59:33,694 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 08:59:39,911 - root -INFO -Application done
2023-06-19 09:01:58,917 - root -INFO -i am in the main method..
2023-06-19 09:01:58,919 - root -INFO -calling spark object
2023-06-19 09:01:58,919 - Create_spark -INFO -get_spark_object method started
2023-06-19 09:01:58,919 - Create_spark -INFO -master is local
2023-06-19 09:02:05,358 - Create_spark -INFO -Spark obejct created.....
2023-06-19 09:02:05,358 - root -INFO -Validating spark object..........
2023-06-19 09:02:05,358 - Validate -WARNING -started the get_current_date method...
2023-06-19 09:02:09,009 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 09:02:09,010 - Validate -WARNING -Validation done , go frwd...
2023-06-19 09:02:09,010 - root -INFO -reading file which is of > parquet
2023-06-19 09:02:09,010 - Ingest -WARNING -load_files method started
2023-06-19 09:02:09,725 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:02:09,725 - root -INFO -displaying file
2023-06-19 09:02:10,575 - root -INFO -here to validate the df
2023-06-19 09:02:10,575 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 09:02:11,130 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 09:02:11,130 - root -INFO -checking for the files in the Fact...
2023-06-19 09:02:11,130 - root -INFO -reading file which is of > csv
2023-06-19 09:02:11,130 - Ingest -WARNING -load_files method started
2023-06-19 09:02:16,921 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:02:16,921 - root -INFO -displaying the df_fact dataframe
2023-06-19 09:02:17,145 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 09:02:17,878 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 09:02:17,879 - root -INFO -implementing data_processing methods...
2023-06-19 09:02:17,879 - Data_processing -WARNING -data_clean method() started...
2023-06-19 09:02:17,879 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 09:02:17,921 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 09:02:17,942 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 09:02:17,996 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 09:02:18,036 - Data_processing -WARNING -concat first and lname 
2023-06-19 09:02:18,054 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 09:02:18,063 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 09:02:18,064 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 09:02:18,087 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 09:02:22,447 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 09:02:22,448 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 09:02:22,448 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 09:02:22,764 - root -INFO -validating schema for the dataframes....
2023-06-19 09:02:22,764 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 09:02:22,765 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 09:02:22,765 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 09:02:22,765 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 09:02:22,766 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 09:02:22,766 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 09:02:22,766 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 09:02:22,766 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:02:22,766 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 09:02:22,767 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 09:02:22,767 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:02:22,869 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 09:02:22,869 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 09:02:23,107 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 09:02:43,458 - root -INFO -data_transformation executing....
2023-06-19 09:02:43,458 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 09:02:43,459 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 09:02:43,484 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 09:02:43,517 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 09:02:43,562 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 09:02:43,562 - root -INFO -displaying the df_report_1
2023-06-19 09:02:52,746 - root -INFO -displaying data_report2 method....
2023-06-19 09:02:52,746 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 09:02:52,746 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 09:02:52,817 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 09:02:58,741 - root -INFO -Application done
2023-06-19 09:06:20,371 - root -INFO -i am in the main method..
2023-06-19 09:06:20,371 - root -INFO -calling spark object
2023-06-19 09:06:20,371 - Create_spark -INFO -get_spark_object method started
2023-06-19 09:06:20,371 - Create_spark -INFO -master is local
2023-06-19 09:06:26,159 - Create_spark -INFO -Spark obejct created.....
2023-06-19 09:06:26,159 - root -INFO -Validating spark object..........
2023-06-19 09:06:26,159 - Validate -WARNING -started the get_current_date method...
2023-06-19 09:06:29,416 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 09:06:29,416 - Validate -WARNING -Validation done , go frwd...
2023-06-19 09:06:29,416 - root -INFO -reading file which is of > parquet
2023-06-19 09:06:29,416 - Ingest -WARNING -load_files method started
2023-06-19 09:06:30,037 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:06:30,038 - root -INFO -displaying file
2023-06-19 09:06:30,767 - root -INFO -here to validate the df
2023-06-19 09:06:30,767 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 09:06:31,302 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 09:06:31,302 - root -INFO -checking for the files in the Fact...
2023-06-19 09:06:31,302 - root -INFO -reading file which is of > csv
2023-06-19 09:06:31,302 - Ingest -WARNING -load_files method started
2023-06-19 09:06:37,420 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:06:37,420 - root -INFO -displaying the df_fact dataframe
2023-06-19 09:06:37,673 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 09:06:39,088 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 09:06:39,088 - root -INFO -implementing data_processing methods...
2023-06-19 09:06:39,088 - Data_processing -WARNING -data_clean method() started...
2023-06-19 09:06:39,088 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 09:06:39,152 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 09:06:39,182 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 09:06:39,286 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 09:06:39,357 - Data_processing -WARNING -concat first and lname 
2023-06-19 09:06:39,390 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 09:06:39,405 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 09:06:39,405 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 09:06:39,434 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 09:06:42,702 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 09:06:42,702 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 09:06:42,702 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 09:06:42,987 - root -INFO -validating schema for the dataframes....
2023-06-19 09:06:42,987 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 09:06:42,988 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 09:06:42,988 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 09:06:42,988 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 09:06:42,988 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 09:06:42,988 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 09:06:42,988 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 09:06:42,988 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:06:42,989 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 09:06:42,989 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 09:06:42,989 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 09:06:42,990 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 09:06:42,990 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:06:43,078 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 09:06:43,079 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 09:06:43,304 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 09:07:07,979 - root -INFO -data_transformation executing....
2023-06-19 09:07:07,979 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 09:07:07,980 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 09:07:08,016 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 09:07:08,071 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 09:07:08,151 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 09:07:08,151 - root -INFO -displaying the df_report_1
2023-06-19 09:07:16,148 - root -INFO -displaying data_report2 method....
2023-06-19 09:07:16,148 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 09:07:16,148 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 09:07:16,178 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 09:07:16,324 - root -INFO -Application done
2023-06-19 09:09:04,994 - root -INFO -i am in the main method..
2023-06-19 09:09:04,994 - root -INFO -calling spark object
2023-06-19 09:09:04,994 - Create_spark -INFO -get_spark_object method started
2023-06-19 09:09:04,994 - Create_spark -INFO -master is local
2023-06-19 09:09:10,375 - Create_spark -INFO -Spark obejct created.....
2023-06-19 09:09:10,375 - root -INFO -Validating spark object..........
2023-06-19 09:09:10,375 - Validate -WARNING -started the get_current_date method...
2023-06-19 09:09:13,733 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 09:09:13,733 - Validate -WARNING -Validation done , go frwd...
2023-06-19 09:09:13,734 - root -INFO -reading file which is of > parquet
2023-06-19 09:09:13,734 - Ingest -WARNING -load_files method started
2023-06-19 09:09:14,322 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:09:14,322 - root -INFO -displaying file
2023-06-19 09:09:15,082 - root -INFO -here to validate the df
2023-06-19 09:09:15,082 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 09:09:15,591 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 09:09:15,592 - root -INFO -checking for the files in the Fact...
2023-06-19 09:09:15,592 - root -INFO -reading file which is of > csv
2023-06-19 09:09:15,592 - Ingest -WARNING -load_files method started
2023-06-19 09:09:21,265 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:09:21,265 - root -INFO -displaying the df_fact dataframe
2023-06-19 09:09:21,483 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 09:09:22,690 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 09:09:22,690 - root -INFO -implementing data_processing methods...
2023-06-19 09:09:22,690 - Data_processing -WARNING -data_clean method() started...
2023-06-19 09:09:22,691 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 09:09:22,761 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 09:09:22,797 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 09:09:22,904 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 09:09:22,971 - Data_processing -WARNING -concat first and lname 
2023-06-19 09:09:23,004 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 09:09:23,024 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 09:09:23,025 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 09:09:23,063 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 09:09:26,711 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 09:09:26,711 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 09:09:26,711 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 09:09:26,995 - root -INFO -validating schema for the dataframes....
2023-06-19 09:09:26,995 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 09:09:26,996 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 09:09:26,996 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 09:09:26,996 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 09:09:26,996 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 09:09:26,996 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 09:09:26,996 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 09:09:26,996 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:09:26,997 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 09:09:26,998 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 09:09:26,998 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:09:27,165 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 09:09:27,165 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 09:09:27,384 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 09:09:51,334 - root -INFO -data_transformation executing....
2023-06-19 09:09:51,335 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 09:09:51,336 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 09:09:51,376 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 09:09:51,435 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 09:09:51,512 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 09:09:51,512 - root -INFO -displaying the df_report_1
2023-06-19 09:09:59,799 - root -INFO -displaying data_report2 method....
2023-06-19 09:09:59,799 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 09:09:59,799 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 09:09:59,876 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 09:10:00,013 - root -INFO -Application done
2023-06-19 09:10:29,323 - root -INFO -i am in the main method..
2023-06-19 09:10:29,323 - root -INFO -calling spark object
2023-06-19 09:10:29,323 - Create_spark -INFO -get_spark_object method started
2023-06-19 09:10:29,324 - Create_spark -INFO -master is local
2023-06-19 09:10:35,663 - Create_spark -INFO -Spark obejct created.....
2023-06-19 09:10:35,663 - root -INFO -Validating spark object..........
2023-06-19 09:10:35,663 - Validate -WARNING -started the get_current_date method...
2023-06-19 09:10:39,824 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 09:10:39,824 - Validate -WARNING -Validation done , go frwd...
2023-06-19 09:10:39,824 - root -INFO -reading file which is of > parquet
2023-06-19 09:10:39,825 - Ingest -WARNING -load_files method started
2023-06-19 09:10:40,788 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:10:40,788 - root -INFO -displaying file
2023-06-19 09:10:41,593 - root -INFO -here to validate the df
2023-06-19 09:10:41,593 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 09:10:42,096 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 09:10:42,097 - root -INFO -checking for the files in the Fact...
2023-06-19 09:10:42,097 - root -INFO -reading file which is of > csv
2023-06-19 09:10:42,097 - Ingest -WARNING -load_files method started
2023-06-19 09:10:47,705 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:10:47,705 - root -INFO -displaying the df_fact dataframe
2023-06-19 09:10:47,914 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 09:10:48,599 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 09:10:48,599 - root -INFO -implementing data_processing methods...
2023-06-19 09:10:48,600 - Data_processing -WARNING -data_clean method() started...
2023-06-19 09:10:48,600 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 09:10:48,676 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 09:10:48,713 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 09:10:48,814 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 09:10:48,876 - Data_processing -WARNING -concat first and lname 
2023-06-19 09:10:48,908 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 09:10:48,926 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 09:10:48,926 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 09:10:48,962 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 09:10:53,306 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 09:10:53,306 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 09:10:53,306 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 09:10:53,589 - root -INFO -validating schema for the dataframes....
2023-06-19 09:10:53,589 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 09:10:53,590 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 09:10:53,591 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 09:10:53,591 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 09:10:53,591 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 09:10:53,591 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 09:10:53,591 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 09:10:53,591 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:10:53,591 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 09:10:53,592 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 09:10:53,593 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 09:10:53,593 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:10:53,743 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 09:10:53,743 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 09:10:53,948 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 09:11:17,270 - root -INFO -data_transformation executing....
2023-06-19 09:11:17,271 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 09:11:17,272 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 09:11:17,307 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 09:11:17,360 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 09:11:17,436 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 09:11:17,436 - root -INFO -displaying the df_report_1
2023-06-19 09:11:25,671 - root -INFO -displaying data_report2 method....
2023-06-19 09:11:25,671 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 09:11:25,671 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 09:11:25,753 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 09:11:25,891 - root -INFO -Application done
2023-06-19 09:13:57,563 - root -INFO -i am in the main method..
2023-06-19 09:13:57,563 - root -INFO -calling spark object
2023-06-19 09:13:57,563 - Create_spark -INFO -get_spark_object method started
2023-06-19 09:13:57,563 - Create_spark -INFO -master is local
2023-06-19 09:14:03,081 - Create_spark -INFO -Spark obejct created.....
2023-06-19 09:14:03,081 - root -INFO -Validating spark object..........
2023-06-19 09:14:03,082 - Validate -WARNING -started the get_current_date method...
2023-06-19 09:14:06,634 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 09:14:06,634 - Validate -WARNING -Validation done , go frwd...
2023-06-19 09:14:06,634 - root -INFO -reading file which is of > parquet
2023-06-19 09:14:06,634 - Ingest -WARNING -load_files method started
2023-06-19 09:14:07,249 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:14:07,249 - root -INFO -displaying file
2023-06-19 09:14:07,994 - root -INFO -here to validate the df
2023-06-19 09:14:07,994 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 09:14:08,514 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 09:14:08,515 - root -INFO -checking for the files in the Fact...
2023-06-19 09:14:08,515 - root -INFO -reading file which is of > csv
2023-06-19 09:14:08,515 - Ingest -WARNING -load_files method started
2023-06-19 09:14:14,477 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:14:14,477 - root -INFO -displaying the df_fact dataframe
2023-06-19 09:14:14,729 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 09:14:16,305 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 09:14:16,305 - root -INFO -implementing data_processing methods...
2023-06-19 09:14:16,305 - Data_processing -WARNING -data_clean method() started...
2023-06-19 09:14:16,306 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 09:14:16,401 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 09:14:16,434 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 09:14:16,580 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 09:14:16,648 - Data_processing -WARNING -concat first and lname 
2023-06-19 09:14:16,679 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 09:14:16,695 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 09:14:16,695 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 09:14:16,729 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 09:14:19,738 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 09:14:19,738 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 09:14:19,738 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 09:14:20,058 - root -INFO -validating schema for the dataframes....
2023-06-19 09:14:20,058 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 09:14:20,059 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 09:14:20,059 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 09:14:20,060 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 09:14:20,060 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 09:14:20,060 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 09:14:20,060 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 09:14:20,060 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:14:20,060 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 09:14:20,061 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 09:14:20,061 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 09:14:20,061 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 09:14:20,061 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 09:14:20,062 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 09:14:20,062 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 09:14:20,062 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 09:14:20,062 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 09:14:20,062 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 09:14:20,062 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 09:14:20,062 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 09:14:20,062 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:14:20,216 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 09:14:20,217 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 09:14:20,408 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 09:14:43,823 - root -INFO -data_transformation executing....
2023-06-19 09:14:43,824 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 09:14:43,825 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 09:14:43,855 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 09:14:43,891 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 09:14:43,936 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 09:14:43,936 - root -INFO -displaying the df_report_1
2023-06-19 09:14:52,473 - root -INFO -displaying data_report2 method....
2023-06-19 09:14:52,473 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 09:14:52,473 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 09:14:52,629 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 09:14:52,880 - root -INFO -Application done
2023-06-19 09:15:40,021 - root -INFO -i am in the main method..
2023-06-19 09:15:40,021 - root -INFO -calling spark object
2023-06-19 09:15:40,021 - Create_spark -INFO -get_spark_object method started
2023-06-19 09:15:40,021 - Create_spark -INFO -master is local
2023-06-19 09:15:45,288 - Create_spark -INFO -Spark obejct created.....
2023-06-19 09:15:45,288 - root -INFO -Validating spark object..........
2023-06-19 09:15:45,288 - Validate -WARNING -started the get_current_date method...
2023-06-19 09:15:48,673 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 09:15:48,674 - Validate -WARNING -Validation done , go frwd...
2023-06-19 09:15:48,674 - root -INFO -reading file which is of > parquet
2023-06-19 09:15:48,674 - Ingest -WARNING -load_files method started
2023-06-19 09:15:49,313 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:15:49,313 - root -INFO -displaying file
2023-06-19 09:15:50,071 - root -INFO -here to validate the df
2023-06-19 09:15:50,071 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 09:15:50,583 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 09:15:50,583 - root -INFO -checking for the files in the Fact...
2023-06-19 09:15:50,583 - root -INFO -reading file which is of > csv
2023-06-19 09:15:50,583 - Ingest -WARNING -load_files method started
2023-06-19 09:15:56,410 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 09:15:56,410 - root -INFO -displaying the df_fact dataframe
2023-06-19 09:15:56,682 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 09:15:57,834 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 09:15:57,834 - root -INFO -implementing data_processing methods...
2023-06-19 09:15:57,834 - Data_processing -WARNING -data_clean method() started...
2023-06-19 09:15:57,834 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 09:15:57,901 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 09:15:57,933 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 09:15:58,043 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 09:15:58,118 - Data_processing -WARNING -concat first and lname 
2023-06-19 09:15:58,159 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 09:15:58,178 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 09:15:58,179 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 09:15:58,218 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 09:16:01,718 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 09:16:01,718 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 09:16:01,718 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 09:16:02,053 - root -INFO -validating schema for the dataframes....
2023-06-19 09:16:02,053 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 09:16:02,054 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 09:16:02,054 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 09:16:02,054 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 09:16:02,054 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 09:16:02,055 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 09:16:02,055 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 09:16:02,055 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:16:02,055 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 09:16:02,055 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 09:16:02,055 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 09:16:02,056 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 09:16:02,056 - Validate -INFO -print_schema done, go frwd....
2023-06-19 09:16:02,214 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 09:16:02,214 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 09:16:02,430 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 09:16:29,102 - root -INFO -data_transformation executing....
2023-06-19 09:16:29,102 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 09:16:29,103 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 09:16:29,131 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 09:16:29,165 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 09:16:29,213 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 09:16:29,214 - root -INFO -displaying the df_report_1
2023-06-19 09:16:38,241 - root -INFO -displaying data_report2 method....
2023-06-19 09:16:38,242 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 09:16:38,242 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 09:16:38,613 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 09:16:48,685 - root -INFO -Application done
2023-06-19 12:04:25,877 - root -INFO -i am in the main method..
2023-06-19 12:04:25,878 - root -INFO -calling spark object
2023-06-19 12:04:25,878 - Create_spark -INFO -get_spark_object method started
2023-06-19 12:04:25,878 - Create_spark -INFO -master is local
2023-06-19 12:04:34,383 - Create_spark -INFO -Spark obejct created.....
2023-06-19 12:04:34,383 - root -INFO -Validating spark object..........
2023-06-19 12:04:34,383 - Validate -WARNING -started the get_current_date method...
2023-06-19 12:04:38,245 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 12:04:38,245 - Validate -WARNING -Validation done , go frwd...
2023-06-19 12:04:38,246 - root -INFO -reading file which is of > parquet
2023-06-19 12:04:38,247 - Ingest -WARNING -load_files method started
2023-06-19 12:04:39,019 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 12:04:39,019 - root -INFO -displaying file
2023-06-19 12:04:39,879 - root -INFO -here to validate the df
2023-06-19 12:04:39,879 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 12:04:40,392 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 12:04:40,392 - root -INFO -checking for the files in the Fact...
2023-06-19 12:04:40,393 - root -INFO -reading file which is of > csv
2023-06-19 12:04:40,393 - Ingest -WARNING -load_files method started
2023-06-19 12:04:46,497 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 12:04:46,497 - root -INFO -displaying the df_fact dataframe
2023-06-19 12:04:46,709 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 12:04:47,803 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 12:04:47,803 - root -INFO -implementing data_processing methods...
2023-06-19 12:04:47,804 - Data_processing -WARNING -data_clean method() started...
2023-06-19 12:04:47,804 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 12:04:47,875 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 12:04:47,909 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 12:04:48,006 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 12:04:48,073 - Data_processing -WARNING -concat first and lname 
2023-06-19 12:04:48,104 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 12:04:48,119 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 12:04:48,119 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 12:04:48,151 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 12:04:51,748 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 12:04:51,749 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 12:04:51,749 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 12:04:52,018 - root -INFO -validating schema for the dataframes....
2023-06-19 12:04:52,018 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 12:04:52,019 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 12:04:52,019 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 12:04:52,019 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 12:04:52,019 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 12:04:52,019 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 12:04:52,019 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 12:04:52,019 - Validate -INFO -print_schema done, go frwd....
2023-06-19 12:04:52,019 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 12:04:52,020 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 12:04:52,021 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 12:04:52,021 - Validate -INFO -print_schema done, go frwd....
2023-06-19 12:04:52,122 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 12:04:52,122 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 12:04:52,363 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 12:05:15,827 - root -INFO -data_transformation executing....
2023-06-19 12:05:15,827 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 12:05:15,828 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 12:05:15,852 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 12:05:15,885 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 12:05:15,930 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 12:05:15,930 - root -INFO -displaying the df_report_1
2023-06-19 12:05:25,439 - root -INFO -displaying data_report2 method....
2023-06-19 12:05:25,440 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 12:05:25,440 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 12:05:25,580 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 12:05:37,368 - root -INFO -writing into hive table
2023-06-19 12:05:37,368 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-06-19 12:05:37,368 - Persist -WARNING -lets create a database....
2023-06-19 12:05:44,184 - Persist -WARNING -No writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-06-19 12:05:55,927 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 12:05:55,927 - root -INFO -successfully written into Hive
2023-06-19 12:05:55,928 - root -INFO -Application done
2023-06-19 12:11:16,200 - root -INFO -i am in the main method..
2023-06-19 12:11:16,200 - root -INFO -calling spark object
2023-06-19 12:11:16,200 - Create_spark -INFO -get_spark_object method started
2023-06-19 12:11:16,200 - Create_spark -INFO -master is local
2023-06-19 12:11:23,154 - Create_spark -INFO -Spark obejct created.....
2023-06-19 12:11:23,154 - root -INFO -Validating spark object..........
2023-06-19 12:11:23,154 - Validate -WARNING -started the get_current_date method...
2023-06-19 12:11:26,949 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 12:11:26,950 - Validate -WARNING -Validation done , go frwd...
2023-06-19 12:11:26,950 - root -INFO -reading file which is of > parquet
2023-06-19 12:11:26,950 - Ingest -WARNING -load_files method started
2023-06-19 12:11:27,732 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 12:11:27,732 - root -INFO -displaying file
2023-06-19 12:11:28,911 - root -INFO -here to validate the df
2023-06-19 12:11:28,911 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 12:11:29,860 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 12:11:29,860 - root -INFO -checking for the files in the Fact...
2023-06-19 12:11:29,861 - root -INFO -reading file which is of > csv
2023-06-19 12:11:29,861 - Ingest -WARNING -load_files method started
2023-06-19 12:11:35,451 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 12:11:35,452 - root -INFO -displaying the df_fact dataframe
2023-06-19 12:11:35,853 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 12:11:36,765 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 12:11:36,765 - root -INFO -implementing data_processing methods...
2023-06-19 12:11:36,766 - Data_processing -WARNING -data_clean method() started...
2023-06-19 12:11:36,766 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 12:11:36,805 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 12:11:36,828 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 12:11:36,878 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 12:11:36,913 - Data_processing -WARNING -concat first and lname 
2023-06-19 12:11:36,931 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 12:11:36,940 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 12:11:36,941 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 12:11:36,958 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 12:11:40,711 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 12:11:40,711 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 12:11:40,711 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 12:11:41,281 - root -INFO -validating schema for the dataframes....
2023-06-19 12:11:41,281 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 12:11:41,284 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 12:11:41,284 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 12:11:41,284 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 12:11:41,284 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 12:11:41,285 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 12:11:41,285 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 12:11:41,285 - Validate -INFO -print_schema done, go frwd....
2023-06-19 12:11:41,285 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 12:11:41,291 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 12:11:41,291 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 12:11:41,292 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 12:11:41,292 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 12:11:41,292 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 12:11:41,292 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 12:11:41,292 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 12:11:41,293 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 12:11:41,293 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 12:11:41,293 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 12:11:41,293 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 12:11:41,293 - Validate -INFO -print_schema done, go frwd....
2023-06-19 12:11:41,487 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 12:11:41,487 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 12:11:41,905 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 12:12:05,345 - root -INFO -data_transformation executing....
2023-06-19 12:12:05,345 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 12:12:05,346 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 12:12:05,372 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 12:12:05,411 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 12:12:05,458 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 12:12:05,458 - root -INFO -displaying the df_report_1
2023-06-19 12:12:14,932 - root -INFO -displaying data_report2 method....
2023-06-19 12:12:14,932 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 12:12:14,932 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 12:12:15,247 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 12:12:25,911 - root -INFO -writing into hive table
2023-06-19 12:12:25,911 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-06-19 12:12:25,911 - Persist -WARNING -lets create a database....
2023-06-19 12:12:31,681 - Persist -WARNING -No writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-06-19 12:12:42,517 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 12:12:42,518 - Persist -WARNING -persisting the data into Hive Table for df_presc
2023-06-19 12:12:42,518 - Persist -WARNING -lets create a database....
2023-06-19 12:12:42,535 - Persist -WARNING -No writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into hive_table by presc_state 
2023-06-19 12:13:30,460 - root -INFO -i am in the main method..
2023-06-19 12:13:30,461 - root -INFO -calling spark object
2023-06-19 12:13:30,461 - Create_spark -INFO -get_spark_object method started
2023-06-19 12:13:30,461 - Create_spark -INFO -master is local
2023-06-19 12:13:36,606 - Create_spark -INFO -Spark obejct created.....
2023-06-19 12:13:36,606 - root -INFO -Validating spark object..........
2023-06-19 12:13:36,606 - Validate -WARNING -started the get_current_date method...
2023-06-19 12:13:40,755 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 12:13:40,755 - Validate -WARNING -Validation done , go frwd...
2023-06-19 12:13:40,756 - root -INFO -reading file which is of > parquet
2023-06-19 12:13:40,756 - Ingest -WARNING -load_files method started
2023-06-19 12:13:42,001 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 12:13:42,001 - root -INFO -displaying file
2023-06-19 12:13:42,885 - root -INFO -here to validate the df
2023-06-19 12:13:42,885 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 12:13:43,439 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 12:13:43,439 - root -INFO -checking for the files in the Fact...
2023-06-19 12:13:43,440 - root -INFO -reading file which is of > csv
2023-06-19 12:13:43,440 - Ingest -WARNING -load_files method started
2023-06-19 12:13:49,101 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 12:13:49,101 - root -INFO -displaying the df_fact dataframe
2023-06-19 12:13:49,311 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 12:13:50,077 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 12:13:50,077 - root -INFO -implementing data_processing methods...
2023-06-19 12:13:50,077 - Data_processing -WARNING -data_clean method() started...
2023-06-19 12:13:50,078 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 12:13:50,117 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 12:13:50,135 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 12:13:50,195 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 12:13:50,232 - Data_processing -WARNING -concat first and lname 
2023-06-19 12:13:50,252 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 12:13:50,263 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 12:13:50,263 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 12:13:50,286 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 12:13:54,108 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 12:13:54,108 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 12:13:54,108 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 12:13:54,409 - root -INFO -validating schema for the dataframes....
2023-06-19 12:13:54,409 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 12:13:54,410 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 12:13:54,410 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 12:13:54,410 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 12:13:54,410 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 12:13:54,410 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 12:13:54,410 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 12:13:54,410 - Validate -INFO -print_schema done, go frwd....
2023-06-19 12:13:54,410 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 12:13:54,411 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 12:13:54,412 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 12:13:54,412 - Validate -INFO -print_schema done, go frwd....
2023-06-19 12:13:54,543 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 12:13:54,543 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 12:13:54,763 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 12:14:18,329 - root -INFO -data_transformation executing....
2023-06-19 12:14:18,330 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 12:14:18,330 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 12:14:18,358 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 12:14:18,393 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 12:14:18,432 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 12:14:18,432 - root -INFO -displaying the df_report_1
2023-06-19 12:14:27,093 - root -INFO -displaying data_report2 method....
2023-06-19 12:14:27,094 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 12:14:27,094 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 12:14:27,229 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 12:14:37,013 - root -INFO -writing into hive table
2023-06-19 12:14:37,013 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-06-19 12:14:37,013 - Persist -WARNING -lets create a database....
2023-06-19 12:14:40,956 - Persist -WARNING -No writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-06-19 12:14:50,633 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 12:14:50,633 - Persist -WARNING -persisting the data into Hive Table for df_presc
2023-06-19 12:14:50,633 - Persist -WARNING -lets create a database....
2023-06-19 12:14:50,653 - Persist -WARNING -No writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into hive_table by presc_state 
2023-06-19 12:15:04,732 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 12:15:04,732 - root -INFO -successfully written into Hive
2023-06-19 12:15:04,732 - root -INFO -Application done
2023-06-19 14:14:54,482 - root -INFO -i am in the main method..
2023-06-19 14:14:54,482 - root -INFO -calling spark object
2023-06-19 14:14:54,482 - Create_spark -INFO -get_spark_object method started
2023-06-19 14:14:54,482 - Create_spark -INFO -master is local
2023-06-19 14:15:01,755 - Create_spark -INFO -Spark object created.....
2023-06-19 14:15:01,755 - root -INFO -Validating spark object..........
2023-06-19 14:15:01,756 - Validate -WARNING -started the get_current_date method...
2023-06-19 14:15:05,477 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 14:15:05,477 - Validate -WARNING -Validation done , go frwd...
2023-06-19 14:15:05,477 - root -INFO -reading file which is of > parquet
2023-06-19 14:15:05,478 - Ingest -WARNING -load_files method started
2023-06-19 14:15:06,247 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 14:15:06,247 - root -INFO -displaying file
2023-06-19 14:15:07,058 - root -INFO -here to validate the df
2023-06-19 14:15:07,058 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 14:15:07,627 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 14:15:07,627 - root -INFO -checking for the files in the Fact...
2023-06-19 14:15:07,627 - root -INFO -reading file which is of > csv
2023-06-19 14:15:07,627 - Ingest -WARNING -load_files method started
2023-06-19 14:15:13,304 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 14:15:13,304 - root -INFO -displaying the df_fact dataframe
2023-06-19 14:15:13,532 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 14:15:14,216 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 14:15:14,216 - root -INFO -implementing data_processing methods...
2023-06-19 14:15:14,217 - Data_processing -WARNING -data_clean method() started...
2023-06-19 14:15:14,217 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 14:15:14,257 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 14:15:14,275 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 14:15:14,323 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 14:15:14,353 - Data_processing -WARNING -concat first and lname 
2023-06-19 14:15:14,368 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 14:15:14,376 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 14:15:14,377 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 14:15:14,395 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 14:15:18,351 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 14:15:18,351 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 14:15:18,351 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 14:15:18,617 - root -INFO -validating schema for the dataframes....
2023-06-19 14:15:18,617 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 14:15:18,619 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 14:15:18,619 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 14:15:18,619 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 14:15:18,619 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 14:15:18,619 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 14:15:18,619 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 14:15:18,619 - Validate -INFO -print_schema done, go frwd....
2023-06-19 14:15:18,620 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 14:15:18,621 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 14:15:18,621 - Validate -INFO -print_schema done, go frwd....
2023-06-19 14:15:18,768 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 14:15:18,769 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 14:15:18,990 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 14:15:40,989 - root -INFO -data_transformation executing....
2023-06-19 14:15:40,989 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 14:15:40,990 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 14:15:41,018 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 14:15:41,052 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 14:15:41,102 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 14:15:41,102 - root -INFO -displaying the df_report_1
2023-06-19 14:15:48,654 - root -INFO -displaying data_report2 method....
2023-06-19 14:15:48,654 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 14:15:48,654 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 14:15:48,797 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 14:15:58,799 - root -INFO -writing into hive table
2023-06-19 14:15:58,799 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-06-19 14:15:58,799 - Persist -WARNING -lets create a database....
2023-06-19 14:16:03,849 - Persist -WARNING -No writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-06-19 14:16:13,498 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 14:16:13,498 - Persist -WARNING -persisting the data into Hive Table for df_presc
2023-06-19 14:16:13,498 - Persist -WARNING -lets create a database....
2023-06-19 14:16:13,529 - Persist -WARNING -No writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into hive_table by presc_state 
2023-06-19 14:16:24,495 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 14:16:24,495 - root -INFO -successfully written into Hive
2023-06-19 14:16:24,496 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-19 14:16:24,496 - Persist -WARNING -executing the data_persist_mysql method...df_city
2023-06-19 14:16:34,545 - Persist -WARNING -Persist_data_mysql method executed succesfully...into city_df
2023-06-19 14:18:30,124 - root -INFO -i am in the main method..
2023-06-19 14:18:30,124 - root -INFO -calling spark object
2023-06-19 14:18:30,124 - Create_spark -INFO -get_spark_object method started
2023-06-19 14:18:30,124 - Create_spark -INFO -master is local
2023-06-19 14:18:36,583 - Create_spark -INFO -Spark object created.....
2023-06-19 14:18:36,583 - root -INFO -Validating spark object..........
2023-06-19 14:18:36,583 - Validate -WARNING -started the get_current_date method...
2023-06-19 14:18:40,219 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 14:18:40,219 - Validate -WARNING -Validation done , go frwd...
2023-06-19 14:18:40,220 - root -INFO -reading file which is of > parquet
2023-06-19 14:18:40,220 - Ingest -WARNING -load_files method started
2023-06-19 14:18:40,888 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 14:18:40,888 - root -INFO -displaying file
2023-06-19 14:18:41,700 - root -INFO -here to validate the df
2023-06-19 14:18:41,700 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 14:18:42,289 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 14:18:42,289 - root -INFO -checking for the files in the Fact...
2023-06-19 14:18:42,290 - root -INFO -reading file which is of > csv
2023-06-19 14:18:42,290 - Ingest -WARNING -load_files method started
2023-06-19 14:18:48,005 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 14:18:48,005 - root -INFO -displaying the df_fact dataframe
2023-06-19 14:18:48,227 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 14:18:48,957 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 14:18:48,957 - root -INFO -implementing data_processing methods...
2023-06-19 14:18:48,957 - Data_processing -WARNING -data_clean method() started...
2023-06-19 14:18:48,957 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 14:18:49,000 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 14:18:49,016 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 14:18:49,075 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 14:18:49,111 - Data_processing -WARNING -concat first and lname 
2023-06-19 14:18:49,130 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 14:18:49,141 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 14:18:49,142 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 14:18:49,163 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 14:18:53,116 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 14:18:53,116 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 14:18:53,116 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 14:18:53,384 - root -INFO -validating schema for the dataframes....
2023-06-19 14:18:53,384 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 14:18:53,385 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 14:18:53,385 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 14:18:53,385 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 14:18:53,385 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 14:18:53,385 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 14:18:53,385 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 14:18:53,385 - Validate -INFO -print_schema done, go frwd....
2023-06-19 14:18:53,385 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 14:18:53,386 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 14:18:53,387 - Validate -INFO -print_schema done, go frwd....
2023-06-19 14:18:53,502 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 14:18:53,502 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 14:18:53,666 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 14:19:14,600 - root -INFO -data_transformation executing....
2023-06-19 14:19:14,601 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 14:19:14,601 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 14:19:14,627 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 14:19:14,666 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 14:19:14,716 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 14:19:14,716 - root -INFO -displaying the df_report_1
2023-06-19 14:19:22,970 - root -INFO -displaying data_report2 method....
2023-06-19 14:19:22,971 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 14:19:22,971 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 14:19:23,243 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 14:19:32,268 - root -INFO -writing into hive table
2023-06-19 14:19:32,269 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-06-19 14:19:32,269 - Persist -WARNING -lets create a database....
2023-06-19 14:19:36,163 - Persist -WARNING -No writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-06-19 14:19:46,208 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 14:19:46,208 - Persist -WARNING -persisting the data into Hive Table for df_presc
2023-06-19 14:19:46,208 - Persist -WARNING -lets create a database....
2023-06-19 14:19:46,224 - Persist -WARNING -No writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into hive_table by presc_state 
2023-06-19 14:19:57,683 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 14:19:57,683 - root -INFO -successfully written into Hive
2023-06-19 14:19:57,684 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-19 14:19:57,684 - Persist -WARNING -executing the data_persist_mysql method...df_city
2023-06-19 14:20:07,999 - Persist -WARNING -Persist_data_mysql method executed succesfully...into city_df
2023-06-19 14:20:07,999 - root -INFO -successfully data inserted into table...
2023-06-19 14:20:08,000 - root -INFO -Application done
2023-06-19 14:40:01,893 - root -INFO -i am in the main method..
2023-06-19 14:40:01,893 - root -INFO -calling spark object
2023-06-19 14:40:01,893 - Create_spark -INFO -get_spark_object method started
2023-06-19 14:40:01,893 - Create_spark -INFO -master is local
2023-06-19 14:40:09,362 - Create_spark -INFO -Spark object created.....
2023-06-19 14:40:09,362 - root -INFO -Validating spark object..........
2023-06-19 14:40:09,362 - Validate -WARNING -started the get_current_date method...
2023-06-19 14:40:14,468 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 14:40:14,469 - Validate -WARNING -Validation done , go frwd...
2023-06-19 14:40:14,469 - root -INFO -reading file which is of > parquet
2023-06-19 14:40:14,469 - Ingest -WARNING -load_files method started
2023-06-19 14:40:15,509 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 14:40:15,510 - root -INFO -displaying file
2023-06-19 14:40:16,388 - root -INFO -here to validate the df
2023-06-19 14:40:16,388 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 14:40:16,944 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 14:40:16,944 - root -INFO -checking for the files in the Fact...
2023-06-19 14:40:16,944 - root -INFO -reading file which is of > csv
2023-06-19 14:40:16,945 - Ingest -WARNING -load_files method started
2023-06-19 14:40:24,226 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 14:40:24,227 - root -INFO -displaying the df_fact dataframe
2023-06-19 14:40:24,657 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 14:40:25,661 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 14:40:25,661 - root -INFO -implementing data_processing methods...
2023-06-19 14:40:25,661 - Data_processing -WARNING -data_clean method() started...
2023-06-19 14:40:25,661 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 14:40:25,701 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 14:40:25,722 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 14:40:25,787 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 14:40:25,829 - Data_processing -WARNING -concat first and lname 
2023-06-19 14:40:25,850 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 14:40:25,857 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 14:40:25,857 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 14:40:25,877 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 14:40:29,635 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 14:40:29,636 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 14:40:29,636 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 14:40:30,568 - root -INFO -validating schema for the dataframes....
2023-06-19 14:40:30,569 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 14:40:30,572 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 14:40:30,573 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 14:40:30,573 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 14:40:30,573 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 14:40:30,573 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 14:40:30,573 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 14:40:30,574 - Validate -INFO -print_schema done, go frwd....
2023-06-19 14:40:30,574 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 14:40:30,578 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 14:40:30,578 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 14:40:30,579 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 14:40:30,579 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 14:40:30,579 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 14:40:30,579 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 14:40:30,580 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 14:40:30,580 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 14:40:30,580 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 14:40:30,580 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 14:40:30,581 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 14:40:30,581 - Validate -INFO -print_schema done, go frwd....
2023-06-19 14:40:31,039 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 14:40:31,039 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 14:40:31,413 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 14:40:56,473 - root -INFO -data_transformation executing....
2023-06-19 14:40:56,474 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 14:40:56,474 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 14:40:56,499 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 14:40:56,529 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 14:40:56,570 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 14:40:56,570 - root -INFO -displaying the df_report_1
2023-06-19 14:41:06,607 - root -INFO -displaying data_report2 method....
2023-06-19 14:41:06,607 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 14:41:06,608 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 14:41:06,751 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 14:41:22,998 - root -INFO -writing into hive table
2023-06-19 14:41:22,999 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-06-19 14:41:22,999 - Persist -WARNING -lets create a database....
2023-06-19 14:41:31,143 - Persist -WARNING -No writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-06-19 14:46:00,141 - root -INFO -i am in the main method..
2023-06-19 14:46:00,141 - root -INFO -calling spark object
2023-06-19 14:46:00,141 - Create_spark -INFO -get_spark_object method started
2023-06-19 14:46:00,141 - Create_spark -INFO -master is local
2023-06-19 14:46:06,389 - Create_spark -INFO -Spark object created.....
2023-06-19 14:46:06,389 - root -INFO -Validating spark object..........
2023-06-19 14:46:06,389 - Validate -WARNING -started the get_current_date method...
2023-06-19 14:46:10,298 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 14:46:10,298 - Validate -WARNING -Validation done , go frwd...
2023-06-19 14:46:10,298 - root -INFO -reading file which is of > parquet
2023-06-19 14:46:10,298 - Ingest -WARNING -load_files method started
2023-06-19 14:46:11,047 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 14:46:11,047 - root -INFO -displaying file
2023-06-19 14:46:11,994 - root -INFO -here to validate the df
2023-06-19 14:46:11,994 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 14:46:13,313 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 14:46:13,314 - root -INFO -checking for the files in the Fact...
2023-06-19 14:46:13,315 - root -INFO -reading file which is of > csv
2023-06-19 14:46:13,315 - Ingest -WARNING -load_files method started
2023-06-19 14:46:19,976 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 14:46:19,976 - root -INFO -displaying the df_fact dataframe
2023-06-19 14:46:20,188 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 14:46:20,996 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 14:46:20,997 - root -INFO -implementing data_processing methods...
2023-06-19 14:46:20,997 - Data_processing -WARNING -data_clean method() started...
2023-06-19 14:46:20,997 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 14:46:21,076 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 14:46:21,110 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 14:46:21,239 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 14:46:21,311 - Data_processing -WARNING -concat first and lname 
2023-06-19 14:46:21,359 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 14:46:21,384 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 14:46:21,384 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 14:46:21,427 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 14:46:25,643 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 14:46:25,643 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 14:46:25,643 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 14:46:25,984 - root -INFO -validating schema for the dataframes....
2023-06-19 14:46:25,985 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 14:46:25,985 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 14:46:25,985 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 14:46:25,986 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 14:46:25,986 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 14:46:25,986 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 14:46:25,986 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 14:46:25,986 - Validate -INFO -print_schema done, go frwd....
2023-06-19 14:46:25,986 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 14:46:25,987 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 14:46:25,987 - Validate -INFO -print_schema done, go frwd....
2023-06-19 14:46:26,100 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 14:46:26,100 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 14:46:26,342 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 14:46:51,071 - root -INFO -data_transformation executing....
2023-06-19 14:46:51,072 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 14:46:51,073 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 14:46:51,113 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 14:46:51,172 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 14:46:51,257 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 14:46:51,258 - root -INFO -displaying the df_report_1
2023-06-19 14:46:59,764 - root -INFO -displaying data_report2 method....
2023-06-19 14:46:59,764 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 14:46:59,764 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 14:46:59,953 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 14:47:10,195 - root -INFO -writing into hive table
2023-06-19 14:47:10,195 - Persist -WARNING -persisting the data into Hive Table for df_city
2023-06-19 14:47:10,195 - Persist -WARNING -lets create a database....
2023-06-19 14:47:15,547 - Persist -WARNING -No writing DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into hive_table by state_name 
2023-06-19 14:47:25,389 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 14:47:25,390 - Persist -WARNING -persisting the data into Hive Table for df_presc
2023-06-19 14:47:25,390 - Persist -WARNING -lets create a database....
2023-06-19 14:47:25,419 - Persist -WARNING -No writing DataFrame[presc_id: int, presc_fullname: string, presc_state: string, Country_name: string, years_of_exp: int, tx_cnt: int, total_day_supply: int, total_drug_cost: double, dense_rank: int] into hive_table by presc_state 
2023-06-19 14:47:37,578 - Persist -WARNING -Data successfully persisted into hive tables...
2023-06-19 14:47:37,578 - root -INFO -successfully written into Hive
2023-06-19 14:47:37,579 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-19 14:47:37,579 - Persist -WARNING -executing the data_persist_mysql method...df_city
2023-06-19 14:47:46,452 - Persist -WARNING -Persist_data_mysql method executed succesfully...into city_df
2023-06-19 14:47:46,452 - root -INFO -successfully data inserted into table...
2023-06-19 14:47:46,453 - root -INFO -Application done
2023-06-19 15:43:37,600 - root -INFO -i am in the main method..
2023-06-19 15:43:37,601 - root -INFO -calling spark object
2023-06-19 15:43:37,601 - Create_spark -INFO -get_spark_object method started
2023-06-19 15:43:37,601 - Create_spark -INFO -master is local
2023-06-19 15:43:44,695 - Create_spark -INFO -Spark object created.....
2023-06-19 15:43:44,695 - root -INFO -Validating spark object..........
2023-06-19 15:43:44,695 - Validate -WARNING -started the get_current_date method...
2023-06-19 15:43:48,808 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 15:43:48,808 - Validate -WARNING -Validation done , go frwd...
2023-06-19 15:43:48,808 - root -INFO -reading file which is of > parquet
2023-06-19 15:43:48,808 - Ingest -WARNING -load_files method started
2023-06-19 15:43:49,645 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 15:43:49,645 - root -INFO -displaying file
2023-06-19 15:43:50,468 - root -INFO -here to validate the df
2023-06-19 15:43:50,468 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 15:43:50,991 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 15:43:50,991 - root -INFO -checking for the files in the Fact...
2023-06-19 15:43:50,991 - root -INFO -reading file which is of > csv
2023-06-19 15:43:50,991 - Ingest -WARNING -load_files method started
2023-06-19 15:43:56,664 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 15:43:56,664 - root -INFO -displaying the df_fact dataframe
2023-06-19 15:43:56,875 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 15:43:57,590 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 15:43:57,590 - root -INFO -implementing data_processing methods...
2023-06-19 15:43:57,590 - Data_processing -WARNING -data_clean method() started...
2023-06-19 15:43:57,590 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 15:43:57,627 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 15:43:57,644 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 15:43:57,695 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 15:43:57,735 - Data_processing -WARNING -concat first and lname 
2023-06-19 15:43:57,767 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 15:43:57,782 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 15:43:57,782 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 15:43:57,819 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 15:44:01,591 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 15:44:01,591 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 15:44:01,591 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 15:44:01,876 - root -INFO -validating schema for the dataframes....
2023-06-19 15:44:01,877 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 15:44:01,877 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 15:44:01,877 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 15:44:01,877 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 15:44:01,877 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 15:44:01,878 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 15:44:01,878 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 15:44:01,878 - Validate -INFO -print_schema done, go frwd....
2023-06-19 15:44:01,878 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 15:44:01,878 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 15:44:01,878 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 15:44:01,879 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 15:44:01,879 - Validate -INFO -print_schema done, go frwd....
2023-06-19 15:44:01,969 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 15:44:01,970 - Validate -INFO -check for nulls method executing.......for df_fact
2023-06-19 15:44:02,177 - Validate -WARNING -Check_for_nulls executed successfully...
2023-06-19 15:44:22,927 - root -INFO -data_transformation executing....
2023-06-19 15:44:22,927 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 15:44:22,928 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 15:44:22,951 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 15:44:22,985 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 15:44:23,029 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 15:44:23,029 - root -INFO -displaying the df_report_1
2023-06-19 15:44:32,487 - root -INFO -displaying data_report2 method....
2023-06-19 15:44:32,487 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 15:44:32,487 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 15:44:32,710 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 15:44:43,314 - root -INFO -extracting files to Output...
2023-06-19 15:44:43,315 - Extraction -WARNING -extract_files method started executing....
2023-06-19 15:46:54,416 - root -INFO -i am in the main method..
2023-06-19 15:46:54,416 - root -INFO -calling spark object
2023-06-19 15:46:54,416 - Create_spark -INFO -get_spark_object method started
2023-06-19 15:46:54,416 - Create_spark -INFO -master is local
2023-06-19 15:46:59,657 - Create_spark -INFO -Spark object created.....
2023-06-19 15:46:59,657 - root -INFO -Validating spark object..........
2023-06-19 15:46:59,657 - Validate -WARNING -started the get_current_date method...
2023-06-19 15:47:02,994 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 15:47:02,994 - Validate -WARNING -Validation done , go frwd...
2023-06-19 15:47:02,995 - root -INFO -reading file which is of > parquet
2023-06-19 15:47:02,995 - Ingest -WARNING -load_files method started
2023-06-19 15:47:03,604 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 15:47:03,604 - root -INFO -displaying file
2023-06-19 15:47:04,369 - root -INFO -here to validate the df
2023-06-19 15:47:04,369 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 15:47:04,880 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 15:47:04,880 - root -INFO -checking for the files in the Fact...
2023-06-19 15:47:04,880 - root -INFO -reading file which is of > csv
2023-06-19 15:47:04,880 - Ingest -WARNING -load_files method started
2023-06-19 15:47:10,569 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 15:47:10,569 - root -INFO -displaying the df_fact dataframe
2023-06-19 15:47:10,787 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 15:47:11,791 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 15:47:11,792 - root -INFO -implementing data_processing methods...
2023-06-19 15:47:11,792 - Data_processing -WARNING -data_clean method() started...
2023-06-19 15:47:11,792 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 15:47:11,861 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 15:47:11,896 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 15:47:12,001 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 15:47:12,066 - Data_processing -WARNING -concat first and lname 
2023-06-19 15:47:12,101 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 15:47:12,118 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 15:47:12,119 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 15:47:12,157 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 15:47:15,711 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 15:47:15,711 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 15:47:15,711 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 15:47:16,007 - root -INFO -validating schema for the dataframes....
2023-06-19 15:47:16,007 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 15:47:16,008 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 15:47:16,008 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 15:47:16,008 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 15:47:16,008 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 15:47:16,008 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 15:47:16,009 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 15:47:16,009 - Validate -INFO -print_schema done, go frwd....
2023-06-19 15:47:16,009 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 15:47:16,010 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 15:47:16,010 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 15:47:16,010 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 15:47:16,010 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 15:47:16,010 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 15:47:16,011 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 15:47:16,011 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 15:47:16,011 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 15:47:16,011 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 15:47:16,011 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 15:47:16,011 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 15:47:16,011 - Validate -INFO -print_schema done, go frwd....
2023-06-19 15:47:16,149 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 15:47:16,149 - root -INFO -data_transformation executing....
2023-06-19 15:47:16,149 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 15:47:16,150 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 15:47:16,182 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 15:47:16,215 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 15:47:16,263 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 15:47:16,263 - root -INFO -displaying the df_report_1
2023-06-19 15:47:16,263 - root -INFO -displaying data_report2 method....
2023-06-19 15:47:16,263 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 15:47:16,263 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 15:47:16,439 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 15:47:16,439 - root -INFO -extracting files to Output...
2023-06-19 15:47:16,439 - Extraction -WARNING -extract_files method started executing....
2023-06-19 15:47:26,576 - Extraction -WARNING -extract_file method successfully executed...
2023-06-19 15:47:26,576 - Extraction -WARNING -extract_files method started executing....
2023-06-19 15:48:03,335 - root -INFO -i am in the main method..
2023-06-19 15:48:03,335 - root -INFO -calling spark object
2023-06-19 15:48:03,335 - Create_spark -INFO -get_spark_object method started
2023-06-19 15:48:03,335 - Create_spark -INFO -master is local
2023-06-19 15:48:08,855 - Create_spark -INFO -Spark object created.....
2023-06-19 15:48:08,856 - root -INFO -Validating spark object..........
2023-06-19 15:48:08,856 - Validate -WARNING -started the get_current_date method...
2023-06-19 15:48:12,285 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 15:48:12,285 - Validate -WARNING -Validation done , go frwd...
2023-06-19 15:48:12,286 - root -INFO -reading file which is of > parquet
2023-06-19 15:48:12,286 - Ingest -WARNING -load_files method started
2023-06-19 15:48:12,922 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 15:48:12,922 - root -INFO -displaying file
2023-06-19 15:48:13,734 - root -INFO -here to validate the df
2023-06-19 15:48:13,734 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 15:48:14,673 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 15:48:14,673 - root -INFO -checking for the files in the Fact...
2023-06-19 15:48:14,674 - root -INFO -reading file which is of > csv
2023-06-19 15:48:14,674 - Ingest -WARNING -load_files method started
2023-06-19 15:48:26,535 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 15:48:26,535 - root -INFO -displaying the df_fact dataframe
2023-06-19 15:48:27,147 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 15:48:28,164 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 15:48:28,164 - root -INFO -implementing data_processing methods...
2023-06-19 15:48:28,165 - Data_processing -WARNING -data_clean method() started...
2023-06-19 15:48:28,165 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 15:48:28,242 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 15:48:28,267 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 15:48:28,350 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 15:48:28,389 - Data_processing -WARNING -concat first and lname 
2023-06-19 15:48:28,416 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 15:48:28,430 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 15:48:28,430 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 15:48:28,457 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 15:48:33,776 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 15:48:33,777 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 15:48:33,777 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 15:48:34,118 - root -INFO -validating schema for the dataframes....
2023-06-19 15:48:34,118 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 15:48:34,119 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 15:48:34,120 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 15:48:34,120 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 15:48:34,120 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 15:48:34,120 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 15:48:34,120 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 15:48:34,120 - Validate -INFO -print_schema done, go frwd....
2023-06-19 15:48:34,120 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 15:48:34,122 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 15:48:34,122 - Validate -INFO -print_schema done, go frwd....
2023-06-19 15:48:34,322 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 15:48:34,322 - root -INFO -data_transformation executing....
2023-06-19 15:48:34,322 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 15:48:34,323 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 15:48:34,370 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 15:48:34,407 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 15:48:34,469 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 15:48:34,469 - root -INFO -displaying the df_report_1
2023-06-19 15:48:34,470 - root -INFO -displaying data_report2 method....
2023-06-19 15:48:34,470 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 15:48:34,470 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 15:48:34,675 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 15:48:34,676 - root -INFO -extracting files to Output...
2023-06-19 15:48:34,676 - Extraction -WARNING -extract_files method started executing....
2023-06-19 16:21:20,495 - root -INFO -i am in the main method..
2023-06-19 16:21:20,495 - root -INFO -calling spark object
2023-06-19 16:21:20,495 - Create_spark -INFO -get_spark_object method started
2023-06-19 16:21:20,495 - Create_spark -INFO -master is local
2023-06-19 16:21:28,712 - Create_spark -INFO -Spark object created.....
2023-06-19 16:21:28,712 - root -INFO -Validating spark object..........
2023-06-19 16:21:28,712 - Validate -WARNING -started the get_current_date method...
2023-06-19 16:21:34,235 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 16:21:34,235 - Validate -WARNING -Validation done , go frwd...
2023-06-19 16:21:34,235 - root -INFO -reading file which is of > parquet
2023-06-19 16:21:34,235 - Ingest -WARNING -load_files method started
2023-06-19 16:21:34,970 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 16:21:34,970 - root -INFO -displaying file
2023-06-19 16:21:36,084 - root -INFO -here to validate the df
2023-06-19 16:21:36,084 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 16:21:37,040 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 16:21:37,040 - root -INFO -checking for the files in the Fact...
2023-06-19 16:21:37,040 - root -INFO -reading file which is of > csv
2023-06-19 16:21:37,040 - Ingest -WARNING -load_files method started
2023-06-19 16:21:44,475 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 16:21:44,476 - root -INFO -displaying the df_fact dataframe
2023-06-19 16:21:44,911 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 16:21:46,445 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 16:21:46,445 - root -INFO -implementing data_processing methods...
2023-06-19 16:21:46,445 - Data_processing -WARNING -data_clean method() started...
2023-06-19 16:21:46,445 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 16:21:46,528 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 16:21:46,561 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 16:21:46,688 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 16:21:46,754 - Data_processing -WARNING -concat first and lname 
2023-06-19 16:21:46,789 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 16:21:46,805 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 16:21:46,806 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 16:21:46,850 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 16:21:51,558 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 16:21:51,558 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 16:21:51,558 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 16:21:52,181 - root -INFO -validating schema for the dataframes....
2023-06-19 16:21:52,182 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 16:21:52,184 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 16:21:52,184 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 16:21:52,184 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 16:21:52,185 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 16:21:52,185 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 16:21:52,185 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 16:21:52,185 - Validate -INFO -print_schema done, go frwd....
2023-06-19 16:21:52,185 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 16:21:52,187 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 16:21:52,188 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 16:21:52,188 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 16:21:52,188 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 16:21:52,188 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 16:21:52,189 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 16:21:52,189 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 16:21:52,189 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 16:21:52,189 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 16:21:52,189 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 16:21:52,190 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 16:21:52,190 - Validate -INFO -print_schema done, go frwd....
2023-06-19 16:21:52,463 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 16:21:52,463 - root -INFO -data_transformation executing....
2023-06-19 16:21:52,463 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 16:21:52,465 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 16:21:52,513 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 16:21:52,555 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 16:21:52,617 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 16:21:52,618 - root -INFO -displaying the df_report_1
2023-06-19 16:21:52,618 - root -INFO -displaying data_report2 method....
2023-06-19 16:21:52,618 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 16:21:52,618 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 16:21:52,837 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 16:21:52,837 - root -INFO -extracting files to Output...
2023-06-19 16:21:52,837 - Extraction -WARNING -extract_files method started executing....
2023-06-19 16:22:10,506 - root -INFO -i am in the main method..
2023-06-19 16:22:10,506 - root -INFO -calling spark object
2023-06-19 16:22:10,506 - Create_spark -INFO -get_spark_object method started
2023-06-19 16:22:10,506 - Create_spark -INFO -master is local
2023-06-19 16:22:17,491 - Create_spark -INFO -Spark object created.....
2023-06-19 16:22:17,491 - root -INFO -Validating spark object..........
2023-06-19 16:22:17,491 - Validate -WARNING -started the get_current_date method...
2023-06-19 16:22:22,418 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 16:22:22,418 - Validate -WARNING -Validation done , go frwd...
2023-06-19 16:22:22,418 - root -INFO -reading file which is of > parquet
2023-06-19 16:22:22,418 - Ingest -WARNING -load_files method started
2023-06-19 16:22:23,355 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 16:22:23,355 - root -INFO -displaying file
2023-06-19 16:22:24,834 - root -INFO -here to validate the df
2023-06-19 16:22:24,834 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 16:22:25,776 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 16:22:25,776 - root -INFO -checking for the files in the Fact...
2023-06-19 16:22:25,777 - root -INFO -reading file which is of > csv
2023-06-19 16:22:25,777 - Ingest -WARNING -load_files method started
2023-06-19 16:22:33,941 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 16:22:33,941 - root -INFO -displaying the df_fact dataframe
2023-06-19 16:22:34,446 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 16:22:35,235 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 16:22:35,235 - root -INFO -implementing data_processing methods...
2023-06-19 16:22:35,235 - Data_processing -WARNING -data_clean method() started...
2023-06-19 16:22:35,235 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 16:22:35,274 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 16:22:35,300 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 16:22:35,356 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 16:22:35,390 - Data_processing -WARNING -concat first and lname 
2023-06-19 16:22:35,408 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 16:22:35,417 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 16:22:35,417 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 16:22:35,440 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 16:22:40,841 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 16:22:40,842 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 16:22:40,842 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 16:22:41,363 - root -INFO -validating schema for the dataframes....
2023-06-19 16:22:41,363 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 16:22:41,364 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 16:22:41,364 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 16:22:41,365 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 16:22:41,365 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 16:22:41,365 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 16:22:41,365 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 16:22:41,365 - Validate -INFO -print_schema done, go frwd....
2023-06-19 16:22:41,365 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 16:22:41,368 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 16:22:41,368 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 16:22:41,368 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 16:22:41,368 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 16:22:41,368 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 16:22:41,368 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 16:22:41,368 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 16:22:41,368 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 16:22:41,369 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 16:22:41,369 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 16:22:41,369 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 16:22:41,369 - Validate -INFO -print_schema done, go frwd....
2023-06-19 16:22:41,597 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 16:22:41,597 - root -INFO -data_transformation executing....
2023-06-19 16:22:41,597 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 16:22:41,599 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 16:22:41,683 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 16:22:41,744 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 16:22:41,833 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 16:22:41,833 - root -INFO -displaying the df_report_1
2023-06-19 16:22:41,834 - root -INFO -displaying data_report2 method....
2023-06-19 16:22:41,834 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 16:22:41,834 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 16:22:42,126 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 16:22:42,127 - root -INFO -extracting files to Output...
2023-06-19 16:22:42,127 - Extraction -WARNING -extract_files method started executing....
2023-06-19 16:24:37,190 - root -INFO -i am in the main method..
2023-06-19 16:24:37,190 - root -INFO -calling spark object
2023-06-19 16:24:37,190 - Create_spark -INFO -get_spark_object method started
2023-06-19 16:24:37,191 - Create_spark -INFO -master is local
2023-06-19 16:24:44,394 - Create_spark -INFO -Spark object created.....
2023-06-19 16:24:44,394 - root -INFO -Validating spark object..........
2023-06-19 16:24:44,395 - Validate -WARNING -started the get_current_date method...
2023-06-19 16:24:49,266 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 19))]
2023-06-19 16:24:49,266 - Validate -WARNING -Validation done , go frwd...
2023-06-19 16:24:49,267 - root -INFO -reading file which is of > parquet
2023-06-19 16:24:49,267 - Ingest -WARNING -load_files method started
2023-06-19 16:24:50,538 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 16:24:50,538 - root -INFO -displaying file
2023-06-19 16:24:52,032 - root -INFO -here to validate the df
2023-06-19 16:24:52,032 - Ingest -WARNING -here to count the records in the df_city
2023-06-19 16:24:52,949 - Ingest -WARNING -number of records 28338 :: 
2023-06-19 16:24:52,949 - root -INFO -checking for the files in the Fact...
2023-06-19 16:24:52,949 - root -INFO -reading file which is of > csv
2023-06-19 16:24:52,949 - Ingest -WARNING -load_files method started
2023-06-19 16:25:01,462 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-19 16:25:01,463 - root -INFO -displaying the df_fact dataframe
2023-06-19 16:25:01,881 - Ingest -WARNING -here to count the records in the df_fact
2023-06-19 16:25:02,742 - Ingest -WARNING -number of records 1329329 :: 
2023-06-19 16:25:02,742 - root -INFO -implementing data_processing methods...
2023-06-19 16:25:02,742 - Data_processing -WARNING -data_clean method() started...
2023-06-19 16:25:02,743 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-19 16:25:02,793 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-19 16:25:02,812 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-19 16:25:02,871 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-19 16:25:02,904 - Data_processing -WARNING -concat first and lname 
2023-06-19 16:25:02,924 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-19 16:25:02,934 - Data_processing -WARNING -now check for null values in all columns
2023-06-19 16:25:02,934 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-19 16:25:02,959 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-19 16:25:08,069 - Data_processing -WARNING -successfully droped the null values....
2023-06-19 16:25:08,069 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-19 16:25:08,069 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-19 16:25:08,415 - root -INFO -validating schema for the dataframes....
2023-06-19 16:25:08,416 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-19 16:25:08,416 - Validate -INFO -	StructField(city,StringType,true)
2023-06-19 16:25:08,417 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-19 16:25:08,417 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-19 16:25:08,417 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-19 16:25:08,417 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-19 16:25:08,417 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-19 16:25:08,417 - Validate -INFO -print_schema done, go frwd....
2023-06-19 16:25:08,417 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-19 16:25:08,418 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-19 16:25:08,418 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-19 16:25:08,418 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-19 16:25:08,418 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-19 16:25:08,419 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-19 16:25:08,419 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-19 16:25:08,419 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-19 16:25:08,419 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-19 16:25:08,419 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-19 16:25:08,419 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-19 16:25:08,419 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-19 16:25:08,419 - Validate -INFO -print_schema done, go frwd....
2023-06-19 16:25:08,591 - root -INFO -checking for null values in dataframes...after processing 
2023-06-19 16:25:08,591 - root -INFO -data_transformation executing....
2023-06-19 16:25:08,591 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-19 16:25:08,592 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-19 16:25:08,646 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-19 16:25:08,706 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-19 16:25:08,790 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-19 16:25:08,791 - root -INFO -displaying the df_report_1
2023-06-19 16:25:08,791 - root -INFO -displaying data_report2 method....
2023-06-19 16:25:08,791 - Data_transformation -WARNING -executing data_report2 method...
2023-06-19 16:25:08,791 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-19 16:25:09,076 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-19 16:25:09,076 - root -INFO -extracting files to Output...
2023-06-19 16:25:09,076 - Extraction -WARNING -extract_files method started executing....
2023-06-19 16:25:23,154 - Extraction -WARNING -extract_file method successfully executed...
2023-06-19 16:25:23,155 - Extraction -WARNING -extract_files method started executing....
2023-06-19 16:25:38,368 - Extraction -WARNING -extract_file method successfully executed...
2023-06-19 16:25:38,368 - root -INFO -extracting files to output completed.....
2023-06-19 16:25:38,368 - root -INFO -writing into hive table
2023-06-19 16:25:38,368 - root -INFO -successfully written into Hive
2023-06-19 16:25:38,371 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-19 16:25:38,372 - root -INFO -successfully data inserted into table...
2023-06-19 16:25:38,372 - root -INFO -Application done
2023-06-20 18:36:07,332 - root -INFO -i am in the main method..
2023-06-20 18:36:07,333 - root -INFO -calling spark object
2023-06-20 18:36:07,333 - Create_spark -INFO -get_spark_object method started
2023-06-20 18:36:07,333 - Create_spark -INFO -master is local
2023-06-20 18:36:21,337 - Create_spark -INFO -Spark object created.....
2023-06-20 18:36:21,337 - root -INFO -Validating spark object..........
2023-06-20 18:36:21,337 - Validate -WARNING -started the get_current_date method...
2023-06-20 18:36:42,826 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 20))]
2023-06-20 18:36:42,826 - Validate -WARNING -Validation done , go frwd...
2023-06-20 18:36:42,826 - root -INFO -reading file which is of > parquet
2023-06-20 18:36:42,827 - Ingest -WARNING -load_files method started
2023-06-20 18:36:44,622 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-20 18:36:44,623 - root -INFO -displaying file
2023-06-20 18:36:46,626 - root -INFO -here to validate the df
2023-06-20 18:36:46,626 - Ingest -WARNING -here to count the records in the df_city
2023-06-20 18:36:48,143 - Ingest -WARNING -number of records 28338 :: 
2023-06-20 18:36:48,144 - root -INFO -checking for the files in the Fact...
2023-06-20 18:36:48,144 - root -INFO -reading file which is of > csv
2023-06-20 18:36:48,145 - Ingest -WARNING -load_files method started
2023-06-20 18:37:00,852 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-20 18:37:00,852 - root -INFO -displaying the df_fact dataframe
2023-06-20 18:37:01,435 - Ingest -WARNING -here to count the records in the df_fact
2023-06-20 18:37:03,163 - Ingest -WARNING -number of records 1329329 :: 
2023-06-20 18:37:03,163 - root -INFO -implementing data_processing methods...
2023-06-20 18:37:03,163 - Data_processing -WARNING -data_clean method() started...
2023-06-20 18:37:03,163 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-20 18:37:03,243 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-20 18:37:03,282 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-20 18:37:03,398 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-20 18:37:03,460 - Data_processing -WARNING -concat first and lname 
2023-06-20 18:37:03,491 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-20 18:37:03,510 - Data_processing -WARNING -now check for null values in all columns
2023-06-20 18:37:03,510 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-20 18:37:03,552 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-20 18:37:10,441 - Data_processing -WARNING -successfully droped the null values....
2023-06-20 18:37:10,442 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-20 18:37:10,442 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-20 18:37:11,331 - root -INFO -validating schema for the dataframes....
2023-06-20 18:37:11,332 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-20 18:37:11,334 - Validate -INFO -	StructField(city,StringType,true)
2023-06-20 18:37:11,335 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-20 18:37:11,335 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-20 18:37:11,335 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-20 18:37:11,335 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-20 18:37:11,337 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-20 18:37:11,337 - Validate -INFO -print_schema done, go frwd....
2023-06-20 18:37:11,337 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-20 18:37:11,340 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-20 18:37:11,341 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-20 18:37:11,341 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-20 18:37:11,341 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-20 18:37:11,341 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-20 18:37:11,341 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-20 18:37:11,342 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-20 18:37:11,342 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-20 18:37:11,342 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-20 18:37:11,342 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-20 18:37:11,342 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-20 18:37:11,343 - Validate -INFO -print_schema done, go frwd....
2023-06-20 18:37:11,775 - root -INFO -checking for null values in dataframes...after processing 
2023-06-20 18:37:11,775 - root -INFO -data_transformation executing....
2023-06-20 18:37:11,775 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-20 18:37:11,778 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-20 18:37:11,838 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-20 18:37:11,910 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-20 18:37:12,008 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-20 18:37:12,008 - root -INFO -displaying the df_report_1
2023-06-20 18:37:12,008 - root -INFO -displaying data_report2 method....
2023-06-20 18:37:12,009 - Data_transformation -WARNING -executing data_report2 method...
2023-06-20 18:37:12,009 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-20 18:37:12,363 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-20 18:37:31,112 - root -INFO -extracting files to Output...
2023-06-20 18:37:31,113 - root -INFO -extracting files to output completed.....
2023-06-20 18:37:31,113 - root -INFO -writing into hive table
2023-06-20 18:37:31,113 - root -INFO -successfully written into Hive
2023-06-20 18:37:31,116 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-20 18:37:31,117 - root -INFO -successfully data inserted into table...
2023-06-20 18:44:05,304 - root -INFO -i am in the main method..
2023-06-20 18:44:05,305 - root -INFO -calling spark object
2023-06-20 18:44:05,305 - Create_spark -INFO -get_spark_object method started
2023-06-20 18:44:05,305 - Create_spark -INFO -master is local
2023-06-20 18:44:42,456 - root -INFO -i am in the main method..
2023-06-20 18:44:42,456 - root -INFO -calling spark object
2023-06-20 18:44:42,456 - Create_spark -INFO -get_spark_object method started
2023-06-20 18:44:42,456 - Create_spark -INFO -master is local
2023-06-20 18:44:54,443 - Create_spark -INFO -Spark object created.....
2023-06-20 18:44:54,443 - root -INFO -Validating spark object..........
2023-06-20 18:44:54,443 - Validate -WARNING -started the get_current_date method...
2023-06-20 18:45:02,018 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 20))]
2023-06-20 18:45:02,018 - Validate -WARNING -Validation done , go frwd...
2023-06-20 18:45:02,019 - root -INFO -reading file which is of > parquet
2023-06-20 18:45:02,019 - Ingest -WARNING -load_files method started
2023-06-20 18:45:03,530 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-20 18:45:03,530 - root -INFO -displaying file
2023-06-20 18:45:05,272 - root -INFO -here to validate the df
2023-06-20 18:45:05,272 - Ingest -WARNING -here to count the records in the df_city
2023-06-20 18:45:06,426 - Ingest -WARNING -number of records 28338 :: 
2023-06-20 18:45:06,426 - root -INFO -checking for the files in the Fact...
2023-06-20 18:45:06,427 - root -INFO -reading file which is of > csv
2023-06-20 18:45:06,427 - Ingest -WARNING -load_files method started
2023-06-20 18:45:18,443 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-20 18:45:18,443 - root -INFO -displaying the df_fact dataframe
2023-06-20 18:45:19,029 - Ingest -WARNING -here to count the records in the df_fact
2023-06-20 18:45:20,897 - Ingest -WARNING -number of records 1329329 :: 
2023-06-20 18:45:20,897 - root -INFO -implementing data_processing methods...
2023-06-20 18:45:20,897 - Data_processing -WARNING -data_clean method() started...
2023-06-20 18:45:20,898 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-20 18:45:20,974 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-20 18:45:21,016 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-20 18:45:21,131 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-20 18:45:21,201 - Data_processing -WARNING -concat first and lname 
2023-06-20 18:45:21,234 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-20 18:45:21,250 - Data_processing -WARNING -now check for null values in all columns
2023-06-20 18:45:21,250 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-20 18:45:21,295 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-20 18:45:28,974 - Data_processing -WARNING -successfully droped the null values....
2023-06-20 18:45:28,974 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-20 18:45:28,974 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-20 18:45:29,635 - root -INFO -validating schema for the dataframes....
2023-06-20 18:45:29,635 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-20 18:45:29,637 - Validate -INFO -	StructField(city,StringType,true)
2023-06-20 18:45:29,638 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-20 18:45:29,638 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-20 18:45:29,638 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-20 18:45:29,638 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-20 18:45:29,638 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-20 18:45:29,639 - Validate -INFO -print_schema done, go frwd....
2023-06-20 18:45:29,639 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-20 18:45:29,641 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-20 18:45:29,641 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-20 18:45:29,641 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-20 18:45:29,642 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-20 18:45:29,642 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-20 18:45:29,642 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-20 18:45:29,643 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-20 18:45:29,643 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-20 18:45:29,643 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-20 18:45:29,643 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-20 18:45:29,643 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-20 18:45:29,644 - Validate -INFO -print_schema done, go frwd....
2023-06-20 18:45:29,902 - root -INFO -checking for null values in dataframes...after processing 
2023-06-20 18:45:29,902 - root -INFO -data_transformation executing....
2023-06-20 18:45:29,902 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-20 18:45:29,904 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-20 18:45:29,969 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-20 18:45:30,040 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-20 18:45:30,164 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-20 18:45:30,165 - root -INFO -displaying the df_report_1
2023-06-20 18:45:30,165 - root -INFO -displaying data_report2 method....
2023-06-20 18:45:30,165 - Data_transformation -WARNING -executing data_report2 method...
2023-06-20 18:45:30,166 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-20 18:45:30,574 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-20 18:45:49,382 - root -INFO -extracting files to Output...
2023-06-20 18:45:49,382 - root -INFO -extracting files to output completed.....
2023-06-20 18:45:49,382 - root -INFO -writing into hive table
2023-06-20 18:45:49,383 - root -INFO -successfully written into Hive
2023-06-20 18:45:49,387 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-20 18:45:49,387 - root -INFO -successfully data inserted into table...
2023-06-20 18:45:49,388 - root -INFO -Application done
2023-06-20 18:49:11,909 - root -INFO -i am in the main method..
2023-06-20 18:49:11,910 - root -INFO -calling spark object
2023-06-20 18:49:11,910 - Create_spark -INFO -get_spark_object method started
2023-06-20 18:49:11,910 - Create_spark -INFO -master is local
2023-06-20 18:49:25,583 - Create_spark -INFO -Spark object created.....
2023-06-20 18:49:25,583 - root -INFO -Validating spark object..........
2023-06-20 18:49:25,583 - Validate -WARNING -started the get_current_date method...
2023-06-20 18:49:32,720 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 20))]
2023-06-20 18:49:32,720 - Validate -WARNING -Validation done , go frwd...
2023-06-20 18:49:32,721 - root -INFO -reading file which is of > parquet
2023-06-20 18:49:32,721 - Ingest -WARNING -load_files method started
2023-06-20 18:49:34,041 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-20 18:49:34,041 - root -INFO -displaying file
2023-06-20 18:49:35,701 - root -INFO -here to validate the df
2023-06-20 18:49:35,701 - Ingest -WARNING -here to count the records in the df_city
2023-06-20 18:49:36,717 - Ingest -WARNING -number of records 28338 :: 
2023-06-20 18:49:36,717 - root -INFO -checking for the files in the Fact...
2023-06-20 18:49:36,718 - root -INFO -reading file which is of > csv
2023-06-20 18:49:36,718 - Ingest -WARNING -load_files method started
2023-06-20 18:49:47,117 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-20 18:49:47,117 - root -INFO -displaying the df_fact dataframe
2023-06-20 18:49:47,723 - Ingest -WARNING -here to count the records in the df_fact
2023-06-20 18:49:49,533 - Ingest -WARNING -number of records 1329329 :: 
2023-06-20 18:49:49,533 - root -INFO -implementing data_processing methods...
2023-06-20 18:49:49,534 - Data_processing -WARNING -data_clean method() started...
2023-06-20 18:49:49,534 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-20 18:49:49,632 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-20 18:49:49,689 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-20 18:49:49,942 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-20 18:49:50,019 - Data_processing -WARNING -concat first and lname 
2023-06-20 18:49:50,055 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-20 18:49:50,074 - Data_processing -WARNING -now check for null values in all columns
2023-06-20 18:49:50,074 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-20 18:49:50,120 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-20 18:49:57,651 - Data_processing -WARNING -successfully droped the null values....
2023-06-20 18:49:57,651 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-20 18:49:57,651 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-20 18:49:58,346 - root -INFO -validating schema for the dataframes....
2023-06-20 18:49:58,347 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-20 18:49:58,349 - Validate -INFO -	StructField(city,StringType,true)
2023-06-20 18:49:58,349 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-20 18:49:58,349 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-20 18:49:58,349 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-20 18:49:58,349 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-20 18:49:58,350 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-20 18:49:58,350 - Validate -INFO -print_schema done, go frwd....
2023-06-20 18:49:58,350 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-20 18:49:58,352 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-20 18:49:58,352 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-20 18:49:58,352 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-20 18:49:58,352 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-20 18:49:58,353 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-20 18:49:58,353 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-20 18:49:58,353 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-20 18:49:58,353 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-20 18:49:58,353 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-20 18:49:58,353 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-20 18:49:58,353 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-20 18:49:58,354 - Validate -INFO -print_schema done, go frwd....
2023-06-20 18:49:58,675 - root -INFO -checking for null values in dataframes...after processing 
2023-06-20 18:49:58,675 - root -INFO -data_transformation executing....
2023-06-20 18:49:58,675 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-20 18:49:58,680 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-20 18:49:58,738 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-20 18:49:58,800 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-20 18:49:58,892 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-20 18:49:58,892 - root -INFO -displaying the df_report_1
2023-06-20 18:49:58,893 - root -INFO -displaying data_report2 method....
2023-06-20 18:49:58,893 - Data_transformation -WARNING -executing data_report2 method...
2023-06-20 18:49:58,893 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-20 18:49:59,218 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-20 18:50:17,387 - root -INFO -extracting files to Output...
2023-06-20 18:50:17,388 - root -INFO -extracting files to output completed.....
2023-06-20 18:50:17,388 - root -INFO -writing into hive table
2023-06-20 18:50:17,388 - root -INFO -successfully written into Hive
2023-06-20 18:50:17,392 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-20 18:50:17,393 - root -INFO -successfully data inserted into table...
2023-06-20 18:50:17,393 - root -INFO -Application done
2023-06-20 19:06:35,080 - root -INFO -i am in the main method..
2023-06-20 19:06:35,081 - root -INFO -calling spark object
2023-06-20 19:06:35,082 - Create_spark -INFO -get_spark_object method started
2023-06-20 19:06:35,084 - Create_spark -INFO -master is local
2023-06-20 19:06:46,898 - Create_spark -INFO -Spark object created.....
2023-06-20 19:06:46,899 - root -INFO -Validating spark object..........
2023-06-20 19:06:46,899 - Validate -WARNING -started the get_current_date method...
2023-06-20 19:06:54,316 - Validate -WARNING -validating spark object with current date-[Row(current_date()=datetime.date(2023, 6, 20))]
2023-06-20 19:06:54,316 - Validate -WARNING -Validation done , go frwd...
2023-06-20 19:06:54,317 - root -INFO -reading file which is of > parquet
2023-06-20 19:06:54,317 - Ingest -WARNING -load_files method started
2023-06-20 19:06:55,892 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-20 19:06:55,892 - root -INFO -displaying file
2023-06-20 19:06:57,787 - root -INFO -here to validate the df
2023-06-20 19:06:57,787 - Ingest -WARNING -here to count the records in the df_city
2023-06-20 19:06:58,907 - Ingest -WARNING -number of records 28338 :: 
2023-06-20 19:06:58,907 - root -INFO -checking for the files in the Fact...
2023-06-20 19:06:58,908 - root -INFO -reading file which is of > csv
2023-06-20 19:06:58,908 - Ingest -WARNING -load_files method started
2023-06-20 19:07:10,418 - Ingest -WARNING -Load_files func done, go fwd..
2023-06-20 19:07:10,418 - root -INFO -displaying the df_fact dataframe
2023-06-20 19:07:10,998 - Ingest -WARNING -here to count the records in the df_fact
2023-06-20 19:07:12,751 - Ingest -WARNING -number of records 1329329 :: 
2023-06-20 19:07:12,752 - root -INFO -implementing data_processing methods...
2023-06-20 19:07:12,752 - Data_processing -WARNING -data_clean method() started...
2023-06-20 19:07:12,752 - Data_processing -WARNING -selecting required columns and converting some of columns into upper case..
2023-06-20 19:07:12,835 - Data_processing -WARNING -working on OLTP dataset and selecting couple of columns and rename...
2023-06-20 19:07:12,873 - Data_processing -WARNING -Adding a new column to df_presc_sel
2023-06-20 19:07:13,017 - Data_processing -WARNING -converting Year_of_exp string to Int and replacing = 
2023-06-20 19:07:13,125 - Data_processing -WARNING -concat first and lname 
2023-06-20 19:07:13,169 - Data_processing -WARNING -now dropping presc_lname and presc_fname
2023-06-20 19:07:13,188 - Data_processing -WARNING -now check for null values in all columns
2023-06-20 19:07:13,188 - Data_processing -WARNING -drop the null values in the respective columns....
2023-06-20 19:07:13,229 - Data_processing -WARNING -fill the null values in tx_cnt with the avg values...
2023-06-20 19:07:20,278 - Data_processing -WARNING -successfully droped the null values....
2023-06-20 19:07:20,278 - Data_processing -WARNING -check for the null values cleaned are not ....
2023-06-20 19:07:20,279 - Data_processing -WARNING -data_clean() method executed done, go frwd....
2023-06-20 19:07:20,982 - root -INFO -validating schema for the dataframes....
2023-06-20 19:07:20,982 - Validate -WARNING -print schema method executing....df_city_sel 
2023-06-20 19:07:20,984 - Validate -INFO -	StructField(city,StringType,true)
2023-06-20 19:07:20,984 - Validate -INFO -	StructField(state_id,StringType,true)
2023-06-20 19:07:20,984 - Validate -INFO -	StructField(state_name,StringType,true)
2023-06-20 19:07:20,984 - Validate -INFO -	StructField(county_name,StringType,true)
2023-06-20 19:07:20,985 - Validate -INFO -	StructField(population,IntegerType,true)
2023-06-20 19:07:20,985 - Validate -INFO -	StructField(zips,StringType,true)
2023-06-20 19:07:20,985 - Validate -INFO -print_schema done, go frwd....
2023-06-20 19:07:20,985 - Validate -WARNING -print schema method executing....df_presc_Sel 
2023-06-20 19:07:20,987 - Validate -INFO -	StructField(presc_id,IntegerType,true)
2023-06-20 19:07:20,987 - Validate -INFO -	StructField(presc_city,StringType,true)
2023-06-20 19:07:20,987 - Validate -INFO -	StructField(presc_state,StringType,true)
2023-06-20 19:07:20,987 - Validate -INFO -	StructField(presc_spclt,StringType,true)
2023-06-20 19:07:20,988 - Validate -INFO -	StructField(drug_name,StringType,true)
2023-06-20 19:07:20,988 - Validate -INFO -	StructField(tx_cnt,IntegerType,true)
2023-06-20 19:07:20,988 - Validate -INFO -	StructField(total_day_supply,IntegerType,true)
2023-06-20 19:07:20,988 - Validate -INFO -	StructField(total_drug_cost,DoubleType,true)
2023-06-20 19:07:20,988 - Validate -INFO -	StructField(years_of_exp,IntegerType,true)
2023-06-20 19:07:20,988 - Validate -INFO -	StructField(Country_name,StringType,false)
2023-06-20 19:07:20,988 - Validate -INFO -	StructField(presc_fullname,StringType,false)
2023-06-20 19:07:20,989 - Validate -INFO -print_schema done, go frwd....
2023-06-20 19:07:21,300 - root -INFO -checking for null values in dataframes...after processing 
2023-06-20 19:07:21,300 - root -INFO -data_transformation executing....
2023-06-20 19:07:21,300 - Data_transformation -WARNING -processing the data_report1 method..
2023-06-20 19:07:21,313 - Data_transformation -WARNING -calculating total zip counts in DataFrame[city: string, state_id: string, state_name: string, county_name: string, population: int, zips: string]
2023-06-20 19:07:21,364 - Data_transformation -WARNING -calculating distinct prescribers and total tx_cnt
2023-06-20 19:07:21,426 - Data_transformation -WARNING -Don't report a city if no prescriber is assigned to it.....lets join df_city_sel and df_presc_grp
2023-06-20 19:07:21,522 - Data_transformation -WARNING -Data_report1 succesfully executed..., go frwd
2023-06-20 19:07:21,522 - root -INFO -displaying the df_report_1
2023-06-20 19:07:21,522 - root -INFO -displaying data_report2 method....
2023-06-20 19:07:21,523 - Data_transformation -WARNING -executing data_report2 method...
2023-06-20 19:07:21,523 - Data_transformation -WARNING -executing the task ::: consider the prescribers only from 20 to 50 years_of_exp and rank the prescribers based on their tx_cnt for each state
2023-06-20 19:07:21,876 - Data_transformation -WARNING -data_report2 method executed...., go frwd...
2023-06-20 19:07:41,129 - root -INFO -extracting files to Output...
2023-06-20 19:07:41,130 - Extraction -WARNING -extract_files method started executing....
2023-06-20 19:07:56,633 - Extraction -WARNING -extract_file method successfully executed...
2023-06-20 19:07:56,633 - Extraction -WARNING -extract_files method started executing....
2023-06-20 19:08:16,927 - Extraction -WARNING -extract_file method successfully executed...
2023-06-20 19:08:16,927 - root -INFO -extracting files to output completed.....
2023-06-20 19:08:16,927 - root -INFO -writing into hive table
2023-06-20 19:08:16,928 - root -INFO -successfully written into Hive
2023-06-20 19:08:16,930 - root -INFO -Now write DataFrame[city: string, state_name: string, county_name: string, population: int, zipcounts: int, presc_counts: bigint] into MYSQL
2023-06-20 19:08:16,932 - root -INFO -successfully data inserted into table...
2023-06-20 19:08:16,932 - root -INFO -Application done
